# CUTLASS å’Œ CuTe å…¥é—¨

## ğŸ“š å­¦ä¹ ç›®æ ‡

1. ç†è§£ CUTLASS çš„åŸºæœ¬æ¦‚å¿µ
2. ç†è§£ CuTe å¼ é‡æŠ½è±¡
3. æŒæ¡åŸºæœ¬çš„ CUTLASS/CuTe ä½¿ç”¨
4. ç†è§£ Flash-Attention ä¸­çš„ CUTLASS/CuTe ä½¿ç”¨

---

## ğŸ¯ CUTLASS ç®€ä»‹

### ä»€ä¹ˆæ˜¯ CUTLASS

**CUTLASS**ï¼ˆCUDA Templates for Linear Algebra Subroutinesï¼‰ï¼š
- NVIDIA çš„ CUDA C++ æ¨¡æ¿åº“
- æä¾›é«˜æ€§èƒ½çš„ GEMMï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰å®ç°
- æ”¯æŒ Tensor Core
- ä½¿ç”¨æ¨¡æ¿å…ƒç¼–ç¨‹å®ç°é«˜åº¦ä¼˜åŒ–

### CUTLASS çš„æ ¸å¿ƒæ¦‚å¿µ

#### 1. Tileï¼ˆç“¦ç‰‡ï¼‰

**å®šä¹‰**ï¼šè®¡ç®—çš„åŸºæœ¬å•ä½ï¼Œå°†å¤§çŸ©é˜µåˆ†æˆå°å—

**å±‚æ¬¡ç»“æ„**ï¼š
```
Thread Block Tile (çº¿ç¨‹å—ç“¦ç‰‡)
  â””â”€â”€ Warp Tile (Warp ç“¦ç‰‡)
        â””â”€â”€ Thread Tile (çº¿ç¨‹ç“¦ç‰‡)
```

**ç¤ºä¾‹**ï¼š
```cuda
// Thread Block Tile: 128Ã—128
// Warp Tile: 64Ã—64
// Thread Tile: 8Ã—8
```

#### 2. Layoutï¼ˆå¸ƒå±€ï¼‰

**å®šä¹‰**ï¼šæè¿°æ•°æ®åœ¨å†…å­˜ä¸­çš„æ’åˆ—æ–¹å¼

**å¸¸è§å¸ƒå±€**ï¼š
- **Row Major**ï¼šæŒ‰è¡Œå­˜å‚¨
- **Column Major**ï¼šæŒ‰åˆ—å­˜å‚¨
- **Swizzle**ï¼šäº¤é”™æ’åˆ—ï¼ˆé¿å… bank conflictï¼‰

#### 3. MMAï¼ˆMatrix Multiply-Accumulateï¼‰

**å®šä¹‰**ï¼šçŸ©é˜µä¹˜ç´¯åŠ æ“ä½œï¼ŒTensor Core çš„æ ¸å¿ƒæ“ä½œ

**Tensor Core**ï¼š
- ä¸“é—¨ç”¨äºçŸ©é˜µä¹˜æ³•
- æ”¯æŒ FP16ã€BF16ã€INT8ã€INT4 ç­‰æ•°æ®ç±»å‹
- æ€§èƒ½æ¯”æ™®é€š CUDA Core é«˜å¾ˆå¤š

---

## ğŸ§© CuTe å¼ é‡æŠ½è±¡

### ä»€ä¹ˆæ˜¯ CuTe

**CuTe**ï¼ˆCUDA Templatesï¼‰ï¼š
- CUTLASS çš„ä¸€éƒ¨åˆ†
- æä¾›å¼ é‡æŠ½è±¡å’Œå¸ƒå±€æè¿°
- ç®€åŒ–å†…å­˜è®¿é—®æ¨¡å¼çš„å®šä¹‰
- ä½¿ç”¨ç°ä»£ C++ æ¨¡æ¿æŠ€æœ¯

### CuTe æ ¸å¿ƒæ¦‚å¿µ

#### 1. Tensorï¼ˆå¼ é‡ï¼‰

**å®šä¹‰**ï¼šå¤šç»´æ•°ç»„çš„æŠ½è±¡

**åˆ›å»ºå¼ é‡**ï¼š
```cuda
#include <cute/tensor.hpp>

using namespace cute;

// ä»æŒ‡é’ˆåˆ›å»ºå¼ é‡
float* data_ptr = ...;
auto tensor = make_tensor(
    make_gmem_ptr(data_ptr),      // å…¨å±€å†…å­˜æŒ‡é’ˆ
    make_shape(M, N),             // å½¢çŠ¶ (M, N)
    make_stride(stride_M, stride_N) // æ­¥é•¿
);
```

#### 2. Shapeï¼ˆå½¢çŠ¶ï¼‰

**å®šä¹‰**ï¼šå¼ é‡çš„ç»´åº¦

**ç¤ºä¾‹**ï¼š
```cuda
// 2D å¼ é‡
auto shape_2d = make_shape(128, 64);  // 128Ã—64

// 3D å¼ é‡
auto shape_3d = make_shape(32, 128, 64);  // 32Ã—128Ã—64

// åŠ¨æ€å½¢çŠ¶
int M = 128, N = 64;
auto shape_dynamic = make_shape(M, N);
```

#### 3. Strideï¼ˆæ­¥é•¿ï¼‰

**å®šä¹‰**ï¼šæ¯ä¸ªç»´åº¦åœ¨å†…å­˜ä¸­çš„æ­¥é•¿

**ç¤ºä¾‹**ï¼š
```cuda
// Row Major å¸ƒå±€
auto stride_row_major = make_stride(N, 1);  // (stride_M, stride_N)

// Column Major å¸ƒå±€
auto stride_col_major = make_stride(1, M);  // (stride_M, stride_N)

// è‡ªå®šä¹‰æ­¥é•¿
auto stride_custom = make_stride(64, 1);  // æ¯è¡Œ 64 ä¸ªå…ƒç´ 
```

#### 4. Layoutï¼ˆå¸ƒå±€ï¼‰

**å®šä¹‰**ï¼šShape å’Œ Stride çš„ç»„åˆ

**åˆ›å»ºå¸ƒå±€**ï¼š
```cuda
auto layout = make_layout(
    make_shape(M, N),
    make_stride(stride_M, stride_N)
);
```

### CuTe æ“ä½œ

#### 1. å¼ é‡è®¿é—®

```cuda
auto tensor = make_tensor(...);

// è®¿é—®å•ä¸ªå…ƒç´ 
float val = tensor(0, 0);

// è®¿é—®ä¸€è¡Œ
auto row = tensor(0, _);  // ç¬¬ 0 è¡Œ

// è®¿é—®ä¸€åˆ—
auto col = tensor(_, 0);  // ç¬¬ 0 åˆ—

// åˆ‡ç‰‡
auto slice = tensor(0, make_range(0, 64));  // ç¬¬ 0 è¡Œï¼Œå‰ 64 åˆ—
```

#### 2. å¼ é‡æ“ä½œ

```cuda
// è½¬ç½®
auto transposed = make_tensor(tensor.data(), 
                              make_shape(N, M),
                              make_stride(stride_N, stride_M));

// é‡å¡‘ï¼ˆReshapeï¼‰
auto reshaped = make_tensor(tensor.data(),
                            make_shape(M * N),
                            make_stride(1));

// å±€éƒ¨åˆ‡ç‰‡ï¼ˆLocal Tileï¼‰
auto local_tile = local_tile(tensor, 
                             make_shape(64, 64),  // Tile å¤§å°
                             make_coord(0, 0));   // Tile ä½ç½®
```

---

## ğŸ”§ Flash-Attention ä¸­çš„ CUTLASS/CuTe ä½¿ç”¨

### Qã€Kã€V å¼ é‡çš„å®šä¹‰

**ä»£ç ç¤ºä¾‹**ï¼ˆç®€åŒ–ï¼‰ï¼š
```cuda
#include <cute/tensor.hpp>
using namespace cute;

// å®šä¹‰ Q å¼ é‡
auto q_tensor = make_tensor(
    make_gmem_ptr(reinterpret_cast<Element*>(params.q_ptr) + 
                   binfo.q_offset(params.q_batch_stride, 
                                 params.q_row_stride, 
                                 bidb)),
    make_shape(binfo.actual_seqlen_q, params.h, params.d),
    make_stride(params.q_row_stride, 
                params.q_head_stride, 
                _1{})
);

// è·å– Q å—
auto q_block = local_tile(q_tensor(_, bidh, _), 
                          Shape<Int<kBlockM>, Int<kHeadDim>>{},
                          make_coord(m_block, 0));
```

### å†…å­˜å¸ƒå±€å®šä¹‰

**Flash-Attention ä¸­çš„å¸ƒå±€**ï¼ˆç®€åŒ–ï¼‰ï¼š
```cuda
// Q çš„å…±äº«å†…å­˜å¸ƒå±€
using SmemLayoutQ = decltype(
    composition(Swizzle<kSwizzle, 3, 3>{},
                Layout<Shape<Int<kBlockM>, Int<kHeadDim>>,
                       Stride<Int<kHeadDim>, _1>>{})
);

// K çš„å…±äº«å†…å­˜å¸ƒå±€
using SmemLayoutK = decltype(
    composition(Swizzle<kSwizzle, 3, 3>{},
                Layout<Shape<Int<kBlockN>, Int<kHeadDim>>,
                       Stride<Int<kHeadDim>, _1>>{})
);
```

**Swizzle**ï¼š
- äº¤é”™æ’åˆ—ï¼Œé¿å… bank conflict
- `kSwizzle` é€šå¸¸æ˜¯ 2 æˆ– 3

### GEMM æ“ä½œ

**ä½¿ç”¨ CUTLASS GEMM**ï¼ˆç®€åŒ–ï¼‰ï¼š
```cuda
// QK^T è®¡ç®—
using TiledMma = TiledMMA<
    MMA_Atom<SM80_16x8x16_F32F16F16F32_TN>,  // Tensor Core é…ç½®
    Layout<Shape<Int<kNWarps>, _1, _1>>,     // Warp å¸ƒå±€
    Tile<Int<16 * kNWarps>, _16, _16>>       // Tile å¤§å°
>;

// æ‰§è¡Œ GEMM
cute::gemm(TiledMma{}, 
           q_tile, k_tile, 
           s_tile);  // s_tile = QK^T
```

---

## ğŸ“ å®é™…ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šç®€å•çš„çŸ©é˜µä¹˜æ³•

```cuda
#include <cute/tensor.hpp>
using namespace cute;

__global__ void simple_gemm(float* A, float* B, float* C, 
                             int M, int N, int K) {
    // åˆ›å»ºå¼ é‡
    auto tensor_A = make_tensor(
        make_gmem_ptr(A),
        make_shape(M, K),
        make_stride(K, 1)  // Row Major
    );
    
    auto tensor_B = make_tensor(
        make_gmem_ptr(B),
        make_shape(K, N),
        make_stride(N, 1)  // Row Major
    );
    
    auto tensor_C = make_tensor(
        make_gmem_ptr(C),
        make_shape(M, N),
        make_stride(N, 1)  // Row Major
    );
    
    // è·å–å½“å‰çº¿ç¨‹å¤„ç†çš„å—
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int tile_M = 64, tile_N = 64;
    int m_tile = tid / (N / tile_N);
    int n_tile = tid % (N / tile_N);
    
    // è·å–å±€éƒ¨å—
    auto A_tile = local_tile(tensor_A, 
                            make_shape(tile_M, K),
                            make_coord(m_tile, 0));
    auto B_tile = local_tile(tensor_B,
                            make_shape(K, tile_N),
                            make_coord(0, n_tile));
    auto C_tile = local_tile(tensor_C,
                            make_shape(tile_M, tile_N),
                            make_coord(m_tile, n_tile));
    
    // è®¡ç®—ï¼ˆç®€åŒ–ï¼Œå®é™…éœ€è¦ä½¿ç”¨ CUTLASS GEMMï¼‰
    for (int i = 0; i < tile_M; i++) {
        for (int j = 0; j < tile_N; j++) {
            float sum = 0.0f;
            for (int k = 0; k < K; k++) {
                sum += A_tile(i, k) * B_tile(k, j);
            }
            C_tile(i, j) = sum;
        }
    }
}
```

### ç¤ºä¾‹ 2ï¼šå…±äº«å†…å­˜å¸ƒå±€

```cuda
__global__ void shared_memory_layout() {
    __shared__ float smem[128][128];
    
    // åˆ›å»ºå…±äº«å†…å­˜å¼ é‡
    auto smem_tensor = make_tensor(
        make_smem_ptr(smem),
        make_shape(128, 128),
        make_stride(128, 1)  // Row Major
    );
    
    // ä½¿ç”¨ Swizzle é¿å… bank conflict
    auto swizzled_layout = composition(
        Swizzle<2, 3, 3>{},  // Swizzle é…ç½®
        make_layout(make_shape(128, 128),
                   make_stride(128, 1))
    );
    
    auto swizzled_tensor = make_tensor(
        make_smem_ptr(smem),
        swizzled_layout
    );
    
    // è®¿é—®ï¼ˆè‡ªåŠ¨åº”ç”¨ Swizzleï¼‰
    int tid = threadIdx.x;
    float val = swizzled_tensor(tid / 32, tid % 32);
}
```

---

## ğŸ¯ Flash-Attention ä¸­çš„å…³é”®ä½¿ç”¨

### 1. å¼ é‡åˆ›å»ºå’Œå¸ƒå±€

**Qã€Kã€V å¼ é‡**ï¼š
```cuda
// ä»å…¨å±€å†…å­˜æŒ‡é’ˆåˆ›å»ºå¼ é‡
auto q_tensor = make_tensor(
    make_gmem_ptr(q_ptr),
    make_shape(seqlen_q, h, d),
    make_stride(q_row_stride, q_head_stride, 1)
);
```

### 2. å±€éƒ¨åˆ‡ç‰‡ï¼ˆLocal Tileï¼‰

**è·å–å—**ï¼š
```cuda
// è·å– Q å—
auto q_block = local_tile(
    q_tensor(_, bidh, _),           // é€‰æ‹©ç‰¹å®šçš„ head
    Shape<Int<kBlockM>, Int<kHeadDim>>{},  // Tile å½¢çŠ¶
    make_coord(m_block, 0)          // Tile åæ ‡
);
```

### 3. å…±äº«å†…å­˜å¸ƒå±€

**Swizzle å¸ƒå±€**ï¼š
```cuda
using SmemLayoutQ = decltype(
    composition(
        Swizzle<kSwizzle, 3, 3>{},  // Swizzle
        Layout<Shape<Int<kBlockM>, Int<kHeadDim>>,
               Stride<Int<kHeadDim>, _1>>{}
    )
);
```

### 4. GEMM æ“ä½œ

**ä½¿ç”¨ CUTLASS GEMM**ï¼š
```cuda
// QK^T
cute::gemm(TiledMma{}, q_tile, k_tile, s_tile);

// PV
cute::gemm(TiledMma{}, p_tile, v_tile, o_tile);
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŠ¿

### CUTLASS çš„ä¼˜åŠ¿

1. **é«˜åº¦ä¼˜åŒ–**ï¼š
   - é’ˆå¯¹ä¸åŒç¡¬ä»¶æ¶æ„ä¼˜åŒ–
   - ä½¿ç”¨ Tensor Core
   - ä¼˜åŒ–çš„å†…å­˜è®¿é—®æ¨¡å¼

2. **çµæ´»æ€§**ï¼š
   - æ¨¡æ¿å…ƒç¼–ç¨‹
   - ç¼–è¯‘æ—¶ä¼˜åŒ–
   - æ”¯æŒå¤šç§æ•°æ®ç±»å‹

3. **æ˜“ç”¨æ€§**ï¼š
   - CuTe ç®€åŒ–äº†å¼ é‡æ“ä½œ
   - æ¸…æ™°çš„æŠ½è±¡
   - æ˜“äºç†è§£å’Œç»´æŠ¤

### Flash-Attention ä¸­çš„ä¼˜åŠ¿

1. **å†…å­˜è®¿é—®ä¼˜åŒ–**ï¼š
   - Swizzle é¿å… bank conflict
   - åˆå¹¶è®¿é—®æé«˜å¸¦å®½

2. **è®¡ç®—ä¼˜åŒ–**ï¼š
   - Tensor Core åŠ é€Ÿ
   - é«˜æ•ˆçš„ GEMM å®ç°

3. **ä»£ç ç®€æ´**ï¼š
   - CuTe ç®€åŒ–äº†ä»£ç 
   - æ˜“äºç†è§£å’Œç»´æŠ¤

---

## ğŸ¯ å…³é”®è¦ç‚¹æ€»ç»“

### CUTLASS è¦ç‚¹

1. **Tile å±‚æ¬¡ç»“æ„**ï¼šThread Block â†’ Warp â†’ Thread
2. **Layout é‡è¦æ€§**ï¼šå½±å“å†…å­˜è®¿é—®æ€§èƒ½
3. **Tensor Core**ï¼šé«˜æ€§èƒ½çŸ©é˜µä¹˜æ³•

### CuTe è¦ç‚¹

1. **å¼ é‡æŠ½è±¡**ï¼šç®€åŒ–å¤šç»´æ•°ç»„æ“ä½œ
2. **å¸ƒå±€æè¿°**ï¼šShape å’Œ Stride çš„ç»„åˆ
3. **å±€éƒ¨åˆ‡ç‰‡**ï¼šæ–¹ä¾¿å¤„ç†å—æ•°æ®

### Flash-Attention ä¸­çš„åº”ç”¨

1. **å¼ é‡åˆ›å»º**ï¼šä»æŒ‡é’ˆåˆ›å»ºå¼ é‡
2. **å±€éƒ¨åˆ‡ç‰‡**ï¼šè·å– Qã€Kã€V å—
3. **å…±äº«å†…å­˜å¸ƒå±€**ï¼šä½¿ç”¨ Swizzle ä¼˜åŒ–
4. **GEMM æ“ä½œ**ï¼šä½¿ç”¨ CUTLASS åŠ é€Ÿ

---

## ğŸ“ å­¦ä¹ æ£€æŸ¥ç‚¹

- [ ] ç†è§£ CUTLASS çš„åŸºæœ¬æ¦‚å¿µ
- [ ] ç†è§£ CuTe å¼ é‡æŠ½è±¡
- [ ] èƒ½å¤Ÿåˆ›å»ºå’Œä½¿ç”¨å¼ é‡
- [ ] ç†è§£å¸ƒå±€çš„ä½œç”¨
- [ ] ç†è§£ Flash-Attention ä¸­çš„ä½¿ç”¨

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- CUTLASS GitHub: https://github.com/NVIDIA/cutlass
- CuTe æ–‡æ¡£: https://github.com/NVIDIA/cutlass/tree/main/cute

### æ•™ç¨‹
- CUTLASS æ•™ç¨‹: https://github.com/NVIDIA/cutlass/tree/main/media/docs
- CuTe æ•™ç¨‹: https://github.com/NVIDIA/cutlass/tree/main/cute/doc

### Flash-Attention æºç 
- `csrc/flash_attn/src/kernel_traits.h` - å¸ƒå±€å®šä¹‰
- `csrc/flash_attn/src/flash_fwd_kernel.h` - å®é™…ä½¿ç”¨

---

**å­¦ä¹ æ—¶é—´**ï¼š2-3 å¤©  
**éš¾åº¦**ï¼šâ­â­â­â­â˜†
