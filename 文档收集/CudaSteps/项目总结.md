# CudaSteps 项目详细总结

本文档详细总结了 CudaSteps 项目中每个章节的题目、CUDA解决思路、具体实现和知识点，包含代码示例和关键概念，便于背诵和复习。

---

## 第1章：GPU硬件与CUDA程序开发工具

### 题目
介绍GPU硬件架构和CUDA开发环境

### CUDA解决思路
- 理解主机(CPU)和设备(GPU)的异构计算架构
- 掌握nvidia-smi工具查看GPU信息
- 了解CUDA开发工具链

### 具体内容

#### 1. GPU硬件架构
- **主机(host)**：起控制作用的CPU
- **设备(device)**：起加速作用的GPU
- 主机和设备都有自己的DRAM，通过PCIe总线连接

#### 2. GPU性能指标
- **浮点数运算峰值(FLOPS)**：
  - 单精度和双精度之分
  - Tesla系列：双精度FLOPS = 单精度FLOPS / 2
  - GeForce系列：双精度FLOPS = 单精度FLOPS / 32
- **GPU内存带宽(显存)**：影响计算性能的重要参数

#### 3. CUDA程序开发工具
- **CUDA**：NVIDIA的GPU编程框架
- **OpenCL**：更通用的异构平台并行编程框架，支持AMD GPU
- **OpenACC**：多公司共同开发的异构并行编程标准

#### 4. CUDA API层次
- **CUDA驱动API**：底层API
- **CUDA运行时API**：高级API，更易用
- 应用程序以主机为出发点，可调用运行时API、驱动API和CUDA库

#### 5. nvidia-smi工具
```bash
nvidia-smi
```
输出信息包括：
- **CUDA Version**：CUDA版本号
- **GPU Name**：GPU名称和设备号
- **TCC/WDDM**：驱动模式
  - WDDM：Windows显示驱动模型
  - TCC：Tesla计算集群模式
- **Compute mode**：计算模式
  - Default：允许多进程
  - E.Process：独占进程模式（不适用于WDDM）
- **Perf**：GPU性能状态（p0最大~p12最小）

环境变量设置：
- `CUDA_VISIBLE_DEVICES`：指定使用的GPU
- `nvidia-smi -g GPU_ID -dm 0`：设置为WDDM模式
- `nvidia-smi -i GPU_ID -c 0`：设置为Default模式

#### 6. GPU架构演进
- **费米(Fermi)**：CUDA 3.2~8，SM20/SM_20，compute_30
- **开普勒(Kepler)**：CUDA 5~10，SM30/SM35/SM37
- **麦克斯韦(Maxwell)**：CUDA 6~11，SM50/SM52/SM53
- **帕斯卡(Pascal)**：CUDA 8~今，SM60/SM61/SM62
- **伏特(Volta)**：CUDA 9~今，SM70/SM72
- **图灵(Turing)**：CUDA 10~今，SM75
- **安培(Ampere)**：CUDA 11~今，SM80/SM86
- **哈珀(Hopper)**：CUDA 12，SM90

### 体现的CUDA知识点
- 主机与设备概念
- GPU性能指标（FLOPS、内存带宽）
- CUDA开发工具和API层次
- GPU架构演进和计算能力

---

## 第2章：CUDA中的线程组织

### 题目
编写第一个CUDA程序，理解线程的组织方式

### CUDA解决思路
- 使用`__global__`限定符定义核函数
- 通过`<<<grid_size, block_size>>>`指定线程配置
- 使用内建变量标识线程身份

### 具体内容

#### 1. CUDA的Hello World程序

**使用nvcc编译C++代码**：
```cuda
// hello.cu
#include <cstdio>
int main() {
    printf("nvcc: hello world!\n");
    return 0;
}
```
编译：`nvcc -o hello.exe hello.cu`

**使用核函数的CUDA程序**：
```cuda
__global__ void hello_from_gpu() {
    printf("gpu: hello world!\n");
}

int main() {
    hello_from_gpu<<<1, 1>>>();
    cudaDeviceSynchronize();
    return 0;
}
```

#### 2. 核函数的特点
- 必须加`__global__`限定符
- 返回类型必须是`void`
- 不支持C++的iostream，但支持printf
- 调用方式：`kernel<<<grid_size, block_size>>>()`

#### 3. 线程组织层次
```
网格(Grid)
  └─ 线程块(Block) [grid_size个]
      └─ 线程(Thread) [block_size个]
          └─ 线程束(Warp) [32个线程]
```

**线程配置**：
- `<<<grid_size, block_size>>>`
- 第一个数字：线程块个数（网格大小）
- 第二个数字：每个线程块中的线程数（线程块大小）
- 总线程数 = grid_size × block_size

#### 4. 内建变量

**线程块大小和网格大小**：
- `blockDim.x/y/z`：线程块在x/y/z方向的线程数
- `gridDim.x/y/z`：网格在x/y/z方向的线程块数

**线程身份标识**：
- `blockIdx.x/y/z`：线程块在网格中的索引，范围[0, gridDim.x/y/z)
- `threadIdx.x/y/z`：线程在线程块中的索引，范围[0, blockDim.x/y/z)

**一维线程索引计算**：
```cuda
int tid = blockDim.x * blockIdx.x + threadIdx.x;
```

**多维线程索引计算**：
```cuda
// 线程在线程块中的ID
int tid = threadIdx.z * (blockDim.x * blockDim.y)
         + threadIdx.y * blockDim.x
         + threadIdx.x;

// 线程块在网格中的ID
int bid = blockIdx.z * (gridDim.x * gridDim.y)
         + blockIdx.y * gridDim.x
         + blockIdx.x;
```

#### 5. 线程束(Warp)
- 一个线程块中连续32个线程组成一个线程束
- 从开普勒架构开始，最大线程块大小是1024
- 最大网格大小是2³¹-1（一维网格）

**多维网格和线程块限制**：
- 网格大小最大值：(2³¹-1, 2¹⁶-1, 2¹⁶-1)
- 线程块大小最大值：(1024, 1024, 64)
- 一个线程块最多1024个线程

#### 6. nvcc编译选项

**计算能力指定**：
```bash
-arch=compute_XY  # 虚拟架构计算能力
-code=sm_ZW        # 真实架构计算能力
```

**多架构编译（胖二进制文件）**：
```bash
-gencode arch=compute_35,code=sm_35
-gencode arch=compute_50,code=sm_50
-gencode arch=compute_60,code=sm_60
```

**实时编译(JIT)**：
```bash
-gencode arch=compute_70,code=compute_70  # 保留PTX代码
```

**简化选项**：
```bash
-arch=sm_XY  # 等价于上述两个gencode
```

### 代码示例
```cuda
__global__ void hello_from_gpu() {
    const int bx = blockIdx.x;
    const int by = blockIdx.y;
    const int bz = blockIdx.z;
    const int tx = threadIdx.x;
    const int ty = threadIdx.y;
    const int tz = threadIdx.z;
    
    printf("gpu: hello world! block(%d,%d,%d) -- thread(%d,%d,%d)\n",
           bx, by, bz, tx, ty, tz);
}

int main() {
    const dim3 block_size(2, 4);
    hello_from_gpu<<<1, block_size>>>();
    cudaDeviceSynchronize();
    return 0;
}
```

### 体现的CUDA知识点
- 核函数定义和调用
- 线程组织层次（Grid→Block→Thread→Warp）
- 内建变量（blockIdx, threadIdx, blockDim, gridDim）
- 线程索引计算
- nvcc编译选项

---

## 第3章：简单CUDA程序的基本框架

### 题目
实现数组相加：`z[i] = x[i] + y[i]`

### CUDA解决思路
1. 主机端分配内存（主机内存和设备内存）
2. 初始化主机数据
3. 将数据从主机复制到设备
4. 调用核函数进行计算
5. 将结果从设备复制回主机
6. 释放内存

### 具体内容

#### 1. CUDA程序基本框架
```cuda
包含头文件

定义常量或宏

声明C++自定义函数和CUDA核函数的原型

int main() {
    1. 分配主机和设备内存
    2. 初始化主机中数据
    3. 将某些数据从主机复制到设备
    4. 调用核函数在设备中计算
    5. 将某些数据从设备复制到主机
    6. 释放主机和设备内存
}

C++自定义函数和CUDA核函数的定义
```

#### 2. 内存管理API

**设备内存分配**：
```cuda
cudaError_t cudaMalloc(void **address, size_t size);
// 示例
double *d_x;
cudaMalloc((void**)&d_x, N * sizeof(double));
```

**主机与设备数据传输**：
```cuda
cudaError_t cudaMemcpy(void *dst, void *src, size_t count, 
                       enum cudaMemcpyKind kind);
// kind: cudaMemcpyHostToDevice, cudaMemcpyDeviceToHost, 
//       cudaMemcpyDeviceToDevice, cudaMemcpyDefault
```

**设备内存释放**：
```cuda
cudaError_t cudaFree(void *address);
```

#### 3. 核函数要求
1. 返回类型必须是`void`，但可以使用`return`（不返回值）
2. 必须使用限定符`__global__`，可加C++限定符
3. 支持C++重载机制
4. 不支持可变参数列表
5. 传给核函数的数组指针必须指向设备内存（统一内存除外）
6. 核函数不能成为类的成员（可用包装函数）
7. 计算能力3.5之前，核函数不能相互调用；之后支持动态并行
8. 核函数在设备中执行

#### 4. 设备函数

**函数限定符**：
- `__global__`：核函数，由主机调用，在设备执行
- `__device__`：设备函数，只能被核函数或其他设备函数调用，在设备执行
- `__host__`：主机函数，在主机调用和执行（可省略）
- `__host__ __device__`：同时编译主机和设备版本

**内联控制**：
- `__noinline__`：建议不要内联
- `__forceinline__`：建议强制内联

**设备函数可以有返回值**

#### 5. 单指令多线程(SIMT)
- 每个线程执行相同的代码
- 通过线程索引区分处理的数据
- 核函数中去掉循环，将数组索引与线程索引一一对应

### 代码示例
```cuda
__global__ void add(const double *x, const double *y, double *z, const int N) {
    const int n = blockDim.x * blockIdx.x + threadIdx.x;
    if (n >= N) return;
    
    z[n] = x[n] + y[n];
}

__device__ double add_in_device(const double x, const double y) {
    return x + y;
}

int main() {
    const int N = 1e4;
    const int M = sizeof(double) * N;
    
    // 分配主机内存
    double *h_x = new double[N];
    double *h_y = (double*)malloc(M);
    double *h_z = (double*)malloc(M);
    
    // 初始化数据
    for (int i = 0; i < N; ++i) {
        h_x[i] = 1.23;
        h_y[i] = 2.34;
    }
    
    // 分配设备内存
    double *d_x, *d_y, *d_z;
    cudaMalloc((void**)&d_x, M);
    cudaMalloc((void**)&d_y, M);
    cudaMalloc((void**)&d_z, M);
    
    // 复制数据到设备
    cudaMemcpy(d_x, h_x, M, cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, h_y, M, cudaMemcpyHostToDevice);
    
    // 调用核函数
    const int block_size = 128;
    const int grid_size = (N + block_size - 1) / block_size;
    add<<<grid_size, block_size>>>(d_x, d_y, d_z, N);
    
    // 复制结果回主机
    cudaMemcpy(h_z, d_z, M, cudaMemcpyDeviceToHost);
    
    // 释放内存
    delete[] h_x;
    free(h_y);
    free(h_z);
    cudaFree(d_x);
    cudaFree(d_y);
    cudaFree(d_z);
    
    return 0;
}
```

### 体现的CUDA知识点
- CUDA程序基本框架
- 内存管理API（cudaMalloc, cudaMemcpy, cudaFree）
- 核函数和设备函数
- SIMT执行模型
- 线程索引与数组索引的对应关系

---

## 第4章：CUDA程序的错误检测

### 题目
实现CUDA运行时错误的检测和报告机制

### CUDA解决思路
- 定义CHECK宏函数检查`cudaError_t`返回值
- 使用`cudaGetLastError()`检测核函数错误
- 使用`cudaDeviceSynchronize()`同步主机和设备
- 使用`cuda-memcheck`工具检测内存错误

### 具体内容

#### 1. 错误检测宏函数
```cuda
#define CHECK(call)                                                     \
do {                                                                    \
    const cudaError_t error_code = call;                                \
    if (error_code != cudaSuccess)                                      \
    {                                                                   \
        printf("CUDA ERROR: \n");                                       \
        printf("    FILE: %s\n", __FILE__);                             \
        printf("    LINE: %d\n", __LINE__);                             \
        printf("    ERROR CODE: %d\n", error_code);                     \
        printf("    ERROR TEXT: %s\n", cudaGetErrorString(error_code)); \
        exit(1);                                                        \
    }                                                                   \
}while(0);
```

**使用方法**：
```cuda
CHECK(cudaMalloc(&d_x, M));
CHECK(cudaMemcpy(d_x, h_x, M, cudaMemcpyHostToDevice));
```

#### 2. 核函数错误检测
核函数没有返回值，需要间接检测：

```cuda
kernel<<<grid_size, block_size>>>(params);
CHECK(cudaGetLastError());  // 捕捉同步前的最后一个错误
CHECK(cudaDeviceSynchronize());  // 同步主机和设备
```

#### 3. 同步机制

**核函数调用的异步性**：
- 核函数调用是**异步的**，主机调用后立即返回
- 主机不会等待核函数执行完成

**显式同步**：
```cuda
cudaDeviceSynchronize();  // 强制同步主机和设备
```

**隐式同步**：
- `cudaMemcpy`会隐式同步主机和设备
- 数据传输是阻塞的

**调试模式**：
```bash
export CUDA_LAUNCH_BLOCKING=1  # 使所有核函数调用变为同步
```

#### 4. CUDA-MEMCHECK工具

**使用方法**：
```bash
cuda-memcheck --tool memcheck [options] app-name [options]
# 或简化为
cuda-memcheck [options] app-name [options]
```

**工具类型**：
- `memcheck`：内存错误检测
- `racecheck`：竞争条件检测
- `initcheck`：未初始化内存检测
- `synccheck`：同步错误检测

### 代码示例
```cuda
#include "error.cuh"

int main() {
    double *d_x;
    CHECK(cudaMalloc(&d_x, M));
    
    kernel<<<grid_size, block_size>>>(d_x);
    CHECK(cudaGetLastError());
    CHECK(cudaDeviceSynchronize());
    
    return 0;
}
```

### 体现的CUDA知识点
- CUDA错误检测机制
- 核函数异步调用
- 同步操作（显式和隐式）
- CUDA调试工具

---

## 第5章：GPU加速的关键

### 题目
分析影响GPU加速效果的关键因素，实现性能计时

### CUDA解决思路
- 使用CUDA事件精确计时
- 比较单精度和双精度性能差异
- 分析数据传输时间与计算时间的比例
- 使用性能分析工具

### 具体内容

#### 1. CUDA事件计时

**C++计时方法**：
- `clock()`函数
- `<chrono>`时间库
- `gettimeofday()`（GCC）
- `QueryPerformanceCounter()`（MSVC）

**CUDA事件计时**：
```cuda
cudaEvent_t start, stop;
CHECK(cudaEventCreate(&start));
CHECK(cudaEventCreate(&stop));
CHECK(cudaEventRecord(start));
cudaEventQuery(start);  // 强制刷新CUDA执行流

// 执行代码

CHECK(cudaEventRecord(stop));
CHECK(cudaEventSynchronize(stop));  // 强制同步
float elapsed_time = 0;
CHECK(cudaEventElapsedTime(&elapsed_time, start, stop));  // 单位：毫秒
```

**计时宏定义**：
```cuda
#define cudaClockStart                                                             \
    float elapsed_time = 0;                                                        \
    float curr_time = 0;                                                           \
    cudaEvent_t start, stop;                                                       \
    CHECK(cudaEventCreate(&start));                                                \
    CHECK(cudaEventCreate(&stop));                                                 \
    CHECK(cudaEventRecord(start));                                                 \
    cudaEventQuery(start);

#define cudaClockCurr                                                              \
    CHECK(cudaEventRecord(stop));                                                  \
    CHECK(cudaEventSynchronize(stop));                                             \
    CHECK(cudaEventElapsedTime(&curr_time, start, stop));                          \
    printf("cuda time cost: %f ms.\n", curr_time - elapsed_time);                  \
    elapsed_time = curr_time;
```

#### 2. 单精度与双精度

**编译选项控制**：
```cuda
#ifdef USE_DP
    typedef double real;
    const real EPSILON = 1.0e-15;
#else
    typedef float real;
    const real EPSILON = 1.0e-6f;
#endif
```

**编译命令**：
```bash
nvcc -O3 -arch=sm_50 -DUSE_DP -o clock.exe add.cu clock.cu main.cpp  # 双精度
nvcc -O3 -arch=sm_50 -o clock.exe add.cu clock.cu main.cpp  # 单精度
```

**性能差异**：
- 双精度版本耗时约为单精度的2倍
- 数据传输时间也相应增加

#### 3. 影响GPU加速的关键因素

**因素1：数据传输开销**
- 主机与设备间数据传输耗时
- 计算强度较小时，数据传输时间占比大
- **策略**：即使GPU计算速度不高，也要放在GPU中，避免过多PCIe传输

**因素2：算术强度**
- **算术强度** = 算术操作工作量 / 内存操作工作量
- 提高算术强度可显著提高GPU相对CPU的加速比
- 设备内存访问速度取决于GPU显存带宽

**因素3：并行规模**
- 并行规模用GPU中的线程数目衡量
- GPU由多个SM（流多处理器）构成
- 每个SM最多驻留线程数：2048（开普勒到伏特）或1024（图灵）
- **要求**：核函数定义的线程总数要接近GPU能驻留的线程总数

#### 4. SM及其占有率

**SM资源**：
- 一定数量的寄存器
- 一定数量的共享内存
- 常量内存缓存
- 纹理内存缓存
- L1缓存
- 2个或4个线程束调度器
- 执行核心

**SM占有率**：
- 尽量让SM占有率≥25%
- 一个SM最多拥有的线程块个数：16（开普勒、图灵）或32（麦克斯韦、帕斯卡、伏特）
- 一个SM最多拥有的线程数：1024（图灵）或2048（其他架构）

#### 5. 性能分析工具

**nvprof**：
```bash
nvprof ./bin/clock
```
注意：不支持7.5以上计算能力的显卡

**Nsight Systems**：
- NVIDIA推荐的新一代性能分析工具
- 支持所有架构

### 代码示例
```cuda
cudaClockStart

// 主机内存分配和数据复制
real *h_x = new real[N];
real *d_x;
CHECK(cudaMalloc(&d_x, M));
CHECK(cudaMemcpy(d_x, h_x, M, cudaMemcpyHostToDevice));

cudaClockCurr  // 输出：host memory malloc and copy: X ms

// 设备内存分配
real *d_y;
CHECK(cudaMalloc(&d_y, M));

cudaClockCurr  // 输出：device memory malloc: X ms

// 核函数执行
add<<<grid_size, block_size>>>(d_x, d_y, d_z, N);

cudaClockCurr  // 输出：kernel function: X ms

// 数据回传
CHECK(cudaMemcpy(h_z, d_z, M, cudaMemcpyDeviceToHost));

cudaClockCurr  // 输出：copy from device to host: X ms
```

### 体现的CUDA知识点
- CUDA事件计时
- 单精度与双精度性能差异
- GPU加速的关键因素（数据传输、算术强度、并行规模）
- SM占有率
- 性能分析工具

---

## 第6章：CUDA内存组织

### 题目
理解CUDA中不同类型内存的特性和使用方法

### CUDA解决思路
- 查询设备内存规格
- 理解不同内存类型的可见范围和生命周期
- 掌握静态全局内存和常量内存的使用

### 具体内容

#### 1. CUDA内存层次结构

```
CPU内存
  ||
  || PCIe总线
  ||
GPU设备内存
  ├─ 全局内存 (Global Memory)
  ├─ 纹理内存 (Texture Memory)
  ├─ 常量内存 (Constant Memory)
  └─ SM层次
      ├─ 共享内存 [block0]  [block1] ...
      └─ 寄存器/局部内存 [thread00] [thread01] ...
```

#### 2. 全局内存 (Global Memory)

**特性**：
- 核函数中所有线程都可以访问
- 可读可写
- 由主机端分配和释放（`cudaMalloc`）
- 容量大（显存），但延迟高、访问速度低
- 生命周期由主机端维护

**静态全局内存**：
```cuda
__device__ real epsilon;      // 单个静态全局内存变量
__device__ real arr[10];       // 固定长度的静态全局内存数组
```

**访问方式**：
- 核函数中可以直接访问，不必以参数形式传递
- 主机中不能直接访问，需要通过`cudaMemcpyToSymbol`和`cudaMemcpyFromSymbol`

#### 3. 常量内存 (Constant Memory)

**特性**：
- 64KB容量
- 可见范围和生命周期与全局内存相同
- 具有缓存，高速访问
- **只读、不可写**

**定义方式**：
```cuda
__constant__ double d_m = 23.33;
__constant__ double d_n[] = {12.2, 34.1, 14.3};
```

**访问方式**：
- 核函数中可以直接访问，不可更改
- 主机中通过`cudaMemcpyToSymbol`和`cudaMemcpyFromSymbol`访问

**适用场景**：
- 数据量小（明显小于4KB）
- 编译期确定
- 仅被读取
- 线程束内所有线程访问同一地址

#### 4. 纹理内存 (Texture Memory)

**特性**：
- 类似常量内存，具有缓存的全局内存
- 只读，有缓存
- 相同可见范围和生命周期

**使用方式**：
```cuda
int __ldg(const int* ptr);  // 通过只读数据缓存读取
```

**注意**：全局内存读取默认就利用了`__ldg()`函数

#### 5. 寄存器 (Register)

**特性**：
- 核函数中不加限定符的变量一般存放在寄存器
- 可读可写
- 仅被一个线程看见
- 生命周期与所属线程相同
- 在芯片上，访问速度最高
- 一个寄存器占32位（4字节）
- 一个双精度浮点数占2个寄存器

**内建变量**：
- `gridDim`、`blockDim`等都保存在特殊寄存器中

#### 6. 局部内存 (Local Memory)

**特性**：
- 全局内存的一部分
- 每个线程最多可以使用512KB
- 用法类似寄存器
- 过多使用会降低性能

#### 7. 共享内存 (Shared Memory)

**特性**：
- 与寄存器类似，位于芯片上，读写速度快
- 对整个线程块可见
- 生命周期与所属线程块一致
- 主要作用：减少全局内存访问，改善全局内存访问模式

#### 8. L1和L2缓存

- **L1缓存**：SM层次
- **L2缓存**：设备层次
- 主要用来缓存全局内存和设备内存的访问

#### 9. 查询设备规格

**API函数**：
```cuda
cudaDeviceProp prop;
CHECK(cudaGetDeviceProperties(&prop, device_id));

printf("Device name: %s\n", prop.name);
printf("Compute capability: %d.%d\n", prop.major, prop.minor);
printf("Amount of global memory: %g GB\n", prop.totalGlobalMem/(1024.0*1024*1024));
printf("Amount of constant memory: %g KB\n", prop.totalConstMem/1024.0);
printf("Maximum grid size: %d, %d, %d\n", prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);
printf("Maximum block size: %d, %d, %d\n", prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);
printf("Number of SMs: %d\n", prop.multiProcessorCount);
printf("Maximum amount of shared memory per block: %g KB\n", prop.sharedMemPerBlock/1024.0);
printf("Maximum amount of shared memory per SM: %g KB\n", prop.sharedMemPerMultiprocessor/1024.0);
printf("Maximum number of registers per block: %d K\n", prop.regsPerBlock/1024);
printf("Maximum number of registers per SM: %d K\n", prop.regsPerMultiprocessor/1024);
printf("Maximum number of threads per block: %d\n", prop.maxThreadsPerBlock);
printf("Maximum number of threads per SM: %d\n", prop.maxThreadsPerMultiProcessor);
```

### 代码示例

**静态全局内存和常量内存**：
```cuda
// 静态全局内存
__device__ int d_x = 1;
__device__ int d_y[2] = {2, 3};

// 常量内存
__constant__ double d_m = 23.33;
__constant__ double d_n[] = {12.2, 34.1, 14.3};

__global__ void add_array() {
    d_y[0] += d_x;
    d_y[1] += d_x;
    printf("d_y: {%d, %d}\n", d_y[0], d_y[1]);
}

__global__ void show() {
    // 常量内存只读
    printf("d_m: %f, d_n: {%f, %f, %f}\n", d_m, d_n[0], d_n[1], d_n[2]);
}

int main() {
    int h_y[2] = {10, 20};
    int h_x = 7;
    
    // 主机向设备复制
    CHECK(cudaMemcpyToSymbol(d_y, h_y, sizeof(int) * 2));
    CHECK(cudaMemcpyToSymbol(d_x, &h_x, sizeof(int)));
    
    add_array<<<1, 1>>>();
    CHECK(cudaDeviceSynchronize());
    
    // 设备向主机复制
    CHECK(cudaMemcpyFromSymbol(h_y, d_y, sizeof(int) * 2));
    CHECK(cudaMemcpyFromSymbol(&h_x, d_x, sizeof(int)));
    
    return 0;
}
```

### 体现的CUDA知识点
- CUDA内存层次结构
- 全局内存、常量内存、纹理内存、寄存器、局部内存、共享内存
- 静态全局内存和常量内存的使用
- 设备规格查询
- 内存访问速度排序

---

## 第7章：全局内存的合理使用

### 题目
实现矩阵转置，优化全局内存访问模式

### CUDA解决思路
- 理解合并访问与非合并访问
- 矩阵转置时优化读写模式
- 使用`__ldg()`函数优化非合并读取

### 具体内容

#### 1. 全局内存访问机制

**内存事务**：
- 一次数据传输处理的数据量：32字节（默认）
- 一次数据传输的首地址必须是32的整数倍
- 一次数据传输只能读取地址为0-31字节、32-63字节等片段的数据

**合并度**：
- **合并度** = 线程束请求的字节数 / 所有内存事务传输的字节数
- 合并度为100%时，所有数据传输的数据都是线程束需要的 → **合并访问**
- 否则为**非合并访问**

#### 2. 合并访问示例

**理想情况（合并访问）**：
- 线程束访问单精度浮点数（4字节）
- 需要32×4=128字节数据
- 如果地址为0-127字节或128-255字节，触发4次数据传输（128/32=4）
- 合并度100%

**非合并访问情况**：
- **不对齐访问**：首地址不是32的整数倍
- **跨越式访问**：线程访问的地址跨度大
- **广播式访问**：所有线程访问同一地址

#### 3. 矩阵转置问题

**问题**：
- 矩阵转置时，读取和写入必有一个是非合并访问
- `dst[nx*N + ny] = src[ny*N + nx]`：读取合并，写入非合并
- `dst[ny*N + nx] = src[nx*N + ny]`：读取非合并，写入合并

**优化策略**：
- 如果读写不能都合并，优先保证写入合并
- 对于非合并读取，使用`__ldg()`通过只读数据缓存

#### 4. 只读数据缓存

**`__ldg()`函数**：
```cuda
int __ldg(const int* ptr);  // 函数原型
```

**使用方式**：
```cuda
dst[ny*N + nx] = __ldg(&src[nx*N + ny]);  // 非合并读取，合并写入
```

**注意**：
- 从帕斯卡架构开始，编译器自动判断并调用`__ldg()`
- 对于开普勒、麦克斯韦架构，需要手动配置

#### 5. 全局内存访问模式对比

**顺序合并访问**：
```cuda
int n = threadIdx.y * blockDim.x + threadIdx.x;
z[n] = sqrt(x[n] + y[n]);
// 线程0-31访问元素0-31，合并度100%
```

**不对齐非合并访问**：
```cuda
int n = threadIdx.y * blockDim.x + threadIdx.x + 1;
z[n] = sqrt(x[n] + y[n]);
// 线程0-31访问元素1-32，需要5次传输，合并度80%
```

**跨越式非合并访问**：
```cuda
int n = blockIdx.x + threadIdx.x * gridDim.x;
z[n] = sqrt(x[n] + y[n]);
// 线程访问元素0, 128, 256...，需要32次传输，合并度12.5%
```

**广播式非合并访问**：
```cuda
int n = threadIdx.x + blockIdx.x * gridDim.x;
z[n] = sqrt(x[0] + y[0]);
// 所有线程访问同一元素，只传输4字节，合并度12.5%
// 更适合使用常量内存
```

### 代码示例

**矩阵转置（合并读取、非合并写入）**：
```cuda
__global__ void transpose1(const real *src, real *dst, const int N) {
    const int nx = threadIdx.x + blockIdx.x * TILE_DIM;
    const int ny = threadIdx.y + blockIdx.y * TILE_DIM;
    
    if (nx < N && ny < N) {
        // 合并读取、非合并写入
        dst[nx*N + ny] = src[ny*N + nx];
    }
}
```

**矩阵转置（非合并读取、合并写入）**：
```cuda
__global__ void transpose2(const real *src, real *dst, const int N) {
    const int nx = threadIdx.x + blockIdx.x * TILE_DIM;
    const int ny = threadIdx.y + blockIdx.y * TILE_DIM;
    
    if (nx < N && ny < N) {
        // 非合并读取（使用__ldg优化）、合并写入
        dst[ny*N + nx] = __ldg(&src[nx*N + ny]);
    }
}
```

### 体现的CUDA知识点
- 合并访问与非合并访问
- 内存事务机制
- 合并度计算
- `__ldg()`函数优化非合并读取
- 矩阵转置的访问模式优化

---

## 第8章：共享内存的合理使用

### 题目
1. 数组归约：计算数组所有元素的和
2. 矩阵转置：使用共享内存优化矩阵转置

### CUDA解决思路

#### 数组归约
- 使用折半归约法
- 将全局内存数据先拷贝到共享内存
- 在共享内存中进行归约，减少全局内存访问
- 使用`__syncthreads()`同步线程块内线程

#### 矩阵转置
- 使用共享内存作为中间缓冲区
- 先将全局内存的非合并访问转为合并访问写入共享内存
- 再从共享内存以合并方式写入全局内存

### 具体内容

#### 1. 共享内存定义

**静态共享内存**：
```cuda
__shared__ real s_x[128];  // 编译期确定大小
```

**动态共享内存**：
```cuda
extern __shared__ real s_x[];  // 运行时指定大小
// 调用时指定：kernel<<<grid_size, block_size, sharedMemSize>>>(...)
```

**特性**：
- 每个线程块有一个该变量的副本
- 线程块内所有线程可以访问
- 生命周期仅在核函数内
- 访问速度远快于全局内存

#### 2. 线程块同步

**`__syncthreads()`函数**：
- 保证线程块内所有线程在执行该语句后面的语句之前，都完全执行了前面的语句
- 实现线程块内线程按照代码顺序执行
- 不同线程块之间依然是独立、异步的

**使用场景**：
- 使用共享内存进行线程块内通信前，必须同步
- 确保共享内存数据对所有线程块内线程都准备好

#### 3. 数组归约算法

**折半归约法**：
```cuda
for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1) {
    if (tid < offset) {
        curr_x[tid] += curr_x[tid + offset];
    }
    __syncthreads();
}
```

**执行过程**：
- 第1轮：线程0-63执行，offset=64
- 第2轮：线程0-31执行，offset=32
- 第3轮：线程0-15执行，offset=16
- ...
- 第7轮：线程0执行，offset=1
- 共需要log₂(128)=7步

**线程利用率**：
- 归约过程中线程利用率逐渐降低
- 平均线程利用率约为1/7

#### 4. 共享内存归约实现

**使用静态共享内存**：
```cuda
__global__ void reduce_shared(const real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    __shared__ real s_x[128];  // 静态共享内存
    s_x[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();  // 同步数据拷贝
    
    for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1) {
        if (tid < offset) {
            s_x[tid] += s_x[tid + offset];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        y[bid] = s_x[0];  // 保存结果到全局内存
    }
}
```

**使用动态共享内存**：
```cuda
__global__ void reduce_shared2(const real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    extern __shared__ real s_x[];  // 动态共享内存
    s_x[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1) {
        if (tid < offset) {
            s_x[tid] += s_x[tid + offset];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        y[bid] = s_x[0];
    }
}

// 调用时指定共享内存大小
int sharedMemSize = block_size * sizeof(real);
reduce_shared2<<<grid_size, block_size, sharedMemSize>>>(d_x, d_y, N);
```

#### 5. 矩阵转置优化

**问题**：矩阵转置时，读写必有一个是非合并访问

**解决方案**：使用共享内存作为中间缓冲区

**实现步骤**：
1. 将全局内存数据以合并方式读取到共享内存
2. 同步线程块
3. 从共享内存以合并方式写入全局内存（转置后）

**代码实现**：
```cuda
__global__ void transpose3(const real *src, real *dst, const int N) {
    __shared__ real s_mat[TILE_DIM][TILE_DIM];  // 二维共享内存
    
    int bx = blockIdx.x * blockDim.x;
    int by = blockIdx.y * blockDim.y;
    int tx = threadIdx.x + bx;
    int ty = threadIdx.y + by;
    
    if (tx < N && ty < N) {
        // 全局内存合并读取，共享内存合并写入
        s_mat[threadIdx.y][threadIdx.x] = src[ty * N + tx];
    }
    __syncthreads();
    
    if (tx < N && ty < N) {
        // 共享内存读取，全局内存合并写入（转置）
        int x = by + threadIdx.x;
        int y = bx + threadIdx.y;
        dst[y * N + x] = s_mat[threadIdx.x][threadIdx.y];
    }
}
```

#### 6. 共享内存Bank冲突

**Bank结构**：
- 共享内存在物理上被分为32个bank
- 每个bank宽度：4字节（非开普勒）或8字节（开普勒）
- 每个bank有多个层（layer）

**Bank冲突**：
- 同一线程束内多个线程访问同一bank的不同层 → 发生冲突
- n路bank冲突导致n次内存事务
- 32路bank冲突：32个线程同时访问同一bank的32个不同层

**避免Bank冲突**：
```cuda
// 原代码：可能发生32路bank冲突
__shared__ real s_mat[TILE_DIM][TILE_DIM];

// 优化：增加列宽，错开bank分布
__shared__ real s_mat[TILE_DIM][TILE_DIM + 1];
```

**注意**：使用共享内存不一定提高性能，需要测试比较

### 代码示例

**完整归约程序**：
```cuda
__global__ void reduce_shared(const real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    __shared__ real s_x[128];
    s_x[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1) {
        if (tid < offset) {
            s_x[tid] += s_x[tid + offset];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        y[bid] = s_x[0];
    }
}

int main() {
    int N = 1e8;
    int block_size = 128;
    int grid_size = (N + block_size - 1) / block_size;
    
    // ... 内存分配和数据初始化 ...
    
    reduce_shared<<<grid_size, block_size>>>(d_x, d_y, N);
    // 然后在主机端对d_y进行二次归约
}
```

### 体现的CUDA知识点
- 共享内存（静态和动态）
- 线程块同步（`__syncthreads()`）
- 折半归约算法
- 共享内存优化矩阵转置
- Bank冲突及避免方法

---

## 第9章：原子函数的合理使用

### 题目
1. 完全在GPU中进行数组归约
2. 邻居列表：找出所有距离小于截断距离的粒子对

### CUDA解决思路

#### GPU归约
- 方法1：使用多个核函数逐步归约
- 方法2：在核函数末尾使用原子函数直接归约到全局变量

#### 邻居列表
- 对每个粒子，遍历所有其他粒子
- 计算距离，判断是否小于截断距离
- 使用原子函数累加邻居数量

### 具体内容

#### 1. 原子函数概念

**原子操作**：
- 一个线程的原子操作可以在不受其他线程任何操作影响下完成对某个数据的"读-改-写"操作
- 原子操作是不可分割的
- 可以操作全局内存或共享内存
- **原子函数没有同步功能**，只是保证操作的原子性

#### 2. 常用原子函数

**加法**：
```cuda
T atomicAdd(T *address, T val);
// 示例
atomicAdd(&sum, value);
```

**减法**：
```cuda
T atomicSub(T *address, T val);
```

**交换**：
```cuda
T atomicExch(T *address, T val);
```

**最小值/最大值**：
```cuda
T atomicMin(T *address, T val);
T atomicMax(T *address, T val);
```

**自增/自减**：
```cuda
T atomicInc(T *address, T val);
T atomicDec(T *address, T val);
```

**比较并交换**：
```cuda
T atomicCAS(T *address, T compare, T val);
```

**返回值**：所有原子函数返回操作前地址的旧值

#### 3. GPU归约实现

**方法1：多核函数归约**：
```cuda
// 第一次归约
reduce<<<grid_size, block_size>>>(d_x, d_y, N);
// 第二次归约（对较短的数组）
reduce<<<1, 1024>>>(d_y, d_y, grid_size);
```

**方法2：原子函数归约**：
```cuda
__global__ void reduce2(real *x, real *y, const int N) {
    int tid = threadIdx.x;
    int ind = tid + blockIdx.x * blockDim.x;
    
    extern __shared__ real curr_x[];
    curr_x[tid] = (ind < N) ? x[ind] : 0.0;
    
    for (int offset = blockDim.x / 2; offset > 0; offset /= 2) {
        if (tid < offset) {
            curr_x[tid] += curr_x[tid + offset];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        atomicAdd(y, curr_x[0]);  // 原子函数累加
    }
}
```

**注意**：
- 原子函数是串行的，会降低并行度
- 应谨慎使用，避免过度使用

#### 4. 邻居列表问题

**问题描述**：
- 给定N个粒子，每个粒子有坐标(x, y)
- 找出所有距离小于截断距离rc的粒子对
- 两个粒子互为邻居的判断：距离 ≤ rc

**CPU算法**：
```cuda
void find_neighbor(int *NN, int *NL, const real *x, const real *y, 
                   const int N, const int M, const real minDis) {
    for (int i = 0; i < N; ++i) {
        NN[i] = 0;
    }
    
    for (int i = 0; i < N; ++i) {
        for (int j = i + 1; j < N; ++j) {
            real dx = x[j] - x[i];
            real dy = y[j] - y[i];
            real dis = dx * dx + dy * dy;  // 比较平方，减少计算
            if (dis < minDis) {
                NL[i*M + NN[i]] = j;
                NN[i]++;
                NL[j*M + NN[j]] = i;
                NN[j]++;
            }
        }
    }
}
```

**GPU实现（使用原子函数）**：
```cuda
__global__ void find_neighbor_atomic(int *NN, int *NL, const real *x, 
                                      const real *y, const int N, const int M, 
                                      const real minDis) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (i < N) {
        NN[i] = 0;
        
        for (int j = i + 1; j < N; ++j) {
            real dx = x[j] - x[i];
            real dy = y[j] - y[i];
            real dis = dx * dx + dy * dy;
            if (dis < minDis) {
                // 原子函数返回旧值
                int old_i_num = atomicAdd(&NN[i], 1);
                NL[i*M + old_i_num] = j;
                
                int old_j_num = atomicAdd(&NN[j], 1);
                NL[j*M + old_j_num] = i;
            }
        }
    }
}
```

**优化技巧**：
- 使用寄存器变量`count`减少对全局变量NN的访问
- 距离判断优先，提高"假"的命中率
- 比较平方距离，避免开方运算

### 代码示例

**完整归约程序（原子函数版本）**：
```cuda
__global__ void reduce2(real *x, real *y, const int N) {
    int tid = threadIdx.x;
    int ind = tid + blockIdx.x * blockDim.x;
    
    extern __shared__ real curr_x[];
    curr_x[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    for (int offset = blockDim.x / 2; offset > 0; offset /= 2) {
        if (tid < offset) {
            curr_x[tid] += curr_x[tid + offset];
        }
        __syncthreads();
    }
    
    if (tid == 0) {
        atomicAdd(y, curr_x[0]);  // 原子函数归约
    }
}

int main() {
    real *d_y2;
    real h_y2 = 0.0;
    CHECK(cudaMalloc(&d_y2, sizeof(real)));
    CHECK(cudaMemcpy(d_y2, &h_y2, sizeof(real), cudaMemcpyHostToDevice));
    
    reduce2<<<grid_size, block_size, block_size*sizeof(real)>>>(d_x, d_y2, N);
    
    CHECK(cudaMemcpy(&h_y2, d_y2, sizeof(real), cudaMemcpyDeviceToHost));
    cout << "reduce2 result: " << h_y2 << endl;
}
```

### 体现的CUDA知识点
- 原子函数概念和使用
- 原子操作的串行特性
- GPU完全归约的实现方法
- 原子函数在邻居列表中的应用
- 原子函数返回值的使用

---

## 第10章：线程束基本函数与协作组

### 题目
优化数组归约程序，使用线程束内函数和协作组

### CUDA解决思路
1. 使用线程束同步替代线程块同步（仅线程束内）
2. 使用线程束洗牌函数实现线程束内归约
3. 使用协作组提供更灵活的同步机制
4. 提高线程利用率

### 具体内容

#### 1. SIMT执行模型

**单指令多线程(SIMT)**：
- 一个GPU被分为若干个SM（流多处理器）
- 核函数中定义的线程块在执行时被分配到还没有完全占满的SM
- 一个block不会被分配到不同的SM
- 一个SM中可以有多个block
- 不同的block之间可以并发也可以顺序执行，一般不能同步

**线程束执行**：
- 一个SM以32个线程（warp）为单位产生、管理、调度、执行线程
- 一个SM可以处理多个block，一个block可以分为若干个warp
- 在同一时刻，一个warp中的线程只能执行一个共同的指令或者闲置

**分支发散(Branch Divergence)**：
```cuda
if (condition) {
    A;
} else {
    B;
}
```
- 满足条件的线程执行A，其他线程闲置
- 然后不满足条件的执行B，其他线程闲置
- 当A和B指令数差不多时，整个warp的执行效率比没有分支的情况低一半

**避免分支发散**：
- 尽量在核函数中避免分支发散
- 有时不可避免，如边界检查：`if (n < N) { ... }`
- 可以通过合并判断语句减少分支发散

#### 2. 线程束同步函数

**`__syncwarp()`函数**：
```cuda
__syncwarp(unsigned mask = 0xffffffff);
```
- 当所涉及的线程都在一个线程束内时，可以替代`__syncthreads()`
- 更加廉价的线程束同步函数
- 参数mask：代表掩码的无符号整型数，默认值0xffffffff（全部32个二进制位都为1）

**掩码(Mask)**：
```cuda
const unsigned FULL_MASK = 0xffffffff;  // 十六进制
// 或
#define FULL_MASK 0xffffffff
```

#### 3. 线程束表决函数

**`__ballot_sync`**：
```cuda
unsigned __ballot_sync(unsigned mask, int predicate);
```
- 如果线程束内第n个线程参与计算（旧掩码）且predicate值非零，则返回的无符号整型数（新掩码）的第n个二进制位为1，否则为0

**`__all_sync`**：
```cuda
int __all_sync(unsigned mask, int predicate);
```
- 线程束内所有参与线程的predicate值均非零，则返回1，否则返回0

**`__any_sync`**：
```cuda
int __any_sync(unsigned mask, int predicate);
```
- 线程束内所有参与线程的predicate值存在非零，则返回1，否则返回0

#### 4. 线程束洗牌函数

**`__shfl_sync`（广播）**：
```cuda
T __shfl_sync(unsigned mask, T v, int srcLane, int w = warpSize);
```
- 参与线程返回标号为srcLane的线程中变量v的值
- 将一个线程中的数据广播到所有线程

**`__shfl_up_sync`（向上平移）**：
```cuda
T __shfl_up_sync(unsigned mask, T v, unsigned d, int w = warpSize);
```
- 标号为t的参与线程返回标号为t-d的线程中变量v的值
- t-d<0的线程返回t线程的变量v
- 将低线程号的值平移到高线程号

**`__shfl_down_sync`（向下平移）**：
```cuda
T __shfl_down_sync(unsigned mask, T v, unsigned d, int w = warpSize);
```
- 标号为t的参与线程返回标号为t+d的线程中变量v的值
- t+d≥w的线程返回t线程的变量v
- 将高线程号的值平移到低线程号

**`__shfl_xor_sync`（两两交换）**：
```cuda
T __shfl_xor_sync(unsigned mask, T v, int laneMask, int w = warpSize);
```
- 标号为t的参与线程返回标号为t^laneMask的线程中变量v的值
- 让线程束内的线程两两交换数据

**参数w**：
- 默认是线程束大小（32）
- 只能取2、4、8、16、32
- 当w<32时，相当于逻辑上的线程束大小是w

**束内索引**：
```cuda
int laneId = threadIdx.x % w;  // 线程索引与束内索引的对应关系
```

#### 5. 协作组(Cooperative Groups)

**头文件**：
```cuda
#include <cooperative_groups.h>
using namespace cooperative_groups;
```

**线程块级别的协作组**：
```cuda
thread_block g = this_thread_block();

g.sync()          <===> __syncthreads()
g.group_index()   <===> blockIdx
g.thread_index()  <===> threadIdx
```

**线程块片(Thread Block Tile)**：
```cuda
// 将线程块划分为线程束
thread_group g32 = tiled_partition(this_thread_block(), 32);

// 继续划分
thread_group g4 = tiled_partition(g32, 4);

// 使用模板，编译期划分
thread_block_tile<32> g32 = tiled_partition<32>(this_thread_block());
thread_block_tile<4> g4 = tiled_partition<4>(this_thread_block());
```

**线程块片函数**：
```cuda
unsigned ballot(int predicate);
int all(int predicate);
int any(int predicate);
T shfl(T v, int srcLane);
T shfl_up(T v, unsigned d);
T shfl_down(T v, unsigned d);
T shfl_xor(T v, unsigned d);
```

**注意**：
- 线程组内的所有线程都要参与代码运行计算
- 线程组内函数不需要指定宽度，因为该宽度就是线程块片的大小

#### 6. 归约优化实现

**使用线程束同步**：
```cuda
__global__ void reduce_syncwarp(real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    extern __shared__ real block_arr[];
    block_arr[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    // 线程块之间的二分求和
    for (int offset = blockDim.x / 2; offset >= 32; offset /= 2) {
        if (tid < offset) {
            block_arr[tid] += block_arr[tid + offset];
        }
        __syncthreads();
    }
    
    // 线程束内的二分求和
    for (int offset = 16; offset > 0; offset /= 2) {
        if (tid < offset) {
            block_arr[tid] += block_arr[tid + offset];
        }
        __syncwarp();  // 线程束同步
    }
    
    if (tid == 0) {
        atomicAdd(y, block_arr[0]);
    }
}
```

**使用线程束洗牌函数**：
```cuda
__global__ void reduce_shfl_down(real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    extern __shared__ real block_arr[];
    block_arr[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    for (int offset = blockDim.x / 2; offset >= 32; offset /= 2) {
        if (tid < offset) {
            block_arr[tid] += block_arr[tid + offset];
        }
        __syncthreads();
    }
    
    // 在线程寄存器上定义变量
    real curr_y = block_arr[tid];
    
    // 使用线程束洗牌函数实现线程束内归约
    for (int offset = 16; offset > 0; offset /= 2) {
        curr_y += __shfl_down_sync(FULL_MASK, curr_y, offset);
    }
    
    if (tid == 0) {
        atomicAdd(y, curr_y);
    }
}
```

**使用协作组**：
```cuda
__global__ void reduce_cp(real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int ind = bid * blockDim.x + tid;
    
    extern __shared__ real block_arr[];
    block_arr[tid] = (ind < N) ? x[ind] : 0.0;
    __syncthreads();
    
    for (int offset = blockDim.x / 2; offset >= 32; offset /= 2) {
        if (tid < offset) {
            block_arr[tid] += block_arr[tid + offset];
        }
        __syncthreads();
    }
    
    real curr_y = block_arr[tid];
    
    // 创建线程块片
    thread_block_tile<32> g32 = tiled_partition<32>(this_thread_block());
    
    for (int offset = 16; offset > 0; offset /= 2) {
        // 线程块片的等价线程束内函数
        curr_y += g32.shfl_down(curr_y, offset);
    }
    
    if (tid == 0) {
        atomicAdd(y, curr_y);
    }
}
```

#### 7. 提高线程利用率

**问题**：
- 归约过程中线程利用率逐渐降低
- 平均线程利用率约为1/7

**解决方案**：
- 在归约前让每个线程处理多个数据
- 使用跨度为`blockDim.x * gridDim.x`保证合并访问

**实现**：
```cuda
__global__ void reduce_cp_grid(const real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    extern __shared__ real block_arr[];
    
    real curr_y = 0.0;
    
    // 在归约前处理计算，提高线程利用率
    const int stride = blockDim.x * gridDim.x;
    for (int n = bid * blockDim.x + tid; n < N; n += stride) {
        curr_y += x[n];
    }
    
    block_arr[tid] = curr_y;
    __syncthreads();
    
    // 后续归约过程...
}
```

#### 8. 避免反复分配设备内存

**问题**：设备内存的分配与释放比较耗时

**解决方案**：使用静态全局内存

```cuda
__device__ real static_y[10240];  // 静态全局内存

real reduce_wrap_static(const real *x, const int N, const int gSize, const int bSize) {
    real *d_y;
    CHECK(cudaGetSymbolAddress((void**)&d_y, static_y));  // 获取静态全局内存地址
    
    reduce_cp_grid<<<gSize, bSize, bSize * sizeof(real)>>>(x, d_y, N);
    reduce_cp_grid<<<1, 1024, 1024*sizeof(real)>>>(d_y, d_y, gSize);
    
    real h_y[1] = {0};
    CHECK(cudaMemcpy(h_y, d_y, sizeof(real), cudaMemcpyDefault));
    
    return h_y[0];
}
```

### 代码示例

**完整优化归约程序**：
```cuda
__global__ void reduce_cp_grid(const real *x, real *y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    extern __shared__ real block_arr[];
    
    real curr_y = 0.0;
    
    // 提高线程利用率：每个线程处理多个数据
    const int stride = blockDim.x * gridDim.x;
    for (int n = bid * blockDim.x + tid; n < N; n += stride) {
        curr_y += x[n];
    }
    
    block_arr[tid] = curr_y;
    __syncthreads();
    
    // 线程块间归约
    for (int offset = blockDim.x / 2; offset >= 32; offset /= 2) {
        if (tid < offset) {
            block_arr[tid] += block_arr[tid + offset];
        }
        __syncthreads();
    }
    
    // 线程束内归约（使用协作组）
    curr_y = block_arr[tid];
    thread_block_tile<32> g32 = tiled_partition<32>(this_thread_block());
    for (int offset = 16; offset > 0; offset /= 2) {
        curr_y += g32.shfl_down(curr_y, offset);
    }
    
    if (tid == 0) {
        y[bid] = curr_y;
    }
}
```

### 体现的CUDA知识点
- SIMT执行模型
- 分支发散
- 线程束同步函数（`__syncwarp()`）
- 线程束表决函数（`__ballot_sync`, `__all_sync`, `__any_sync`）
- 线程束洗牌函数（`__shfl_sync`系列）
- 协作组（Cooperative Groups）
- 线程利用率优化
- 静态全局内存的使用

---

## 第11章：CUDA流

### 题目
1. 主机和设备计算重叠
2. 多个核函数并行执行
3. 核函数执行与数据传输重叠

### CUDA解决思路

#### 主机-设备重叠
- 核函数调用是异步的
- 在核函数调用后执行主机计算，实现重叠

#### 多核函数并行
- 创建多个非默认CUDA流
- 将不同核函数分配到不同流中

#### 核函数-数据传输重叠
- 使用`cudaMemcpyAsync`异步传输
- 主机内存必须是不可分页内存
- 将数据传输和核函数分配到不同流

### 具体内容

#### 1. CUDA流概念

**定义**：
- 一个CUDA流是指由主机发出的、在设备中执行的CUDA操作序列
- 任何CUDA操作都存在于某个CUDA流
- **默认流（default stream）**：也称为空流
- 非默认的CUDA流（非空流）都在主机端产生与销毁

**表示**：
```cuda
cudaStream_t stream;  // CUDA流类型
```

#### 2. CUDA流的创建与销毁

**创建**：
```cuda
cudaStream_t stream;
CHECK(cudaStreamCreate(&stream));
```

**销毁**：
```cuda
CHECK(cudaStreamDestroy(stream));
```

**检查流执行状态**：
```cuda
cudaError_t cudaStreamSynchronize(cudaStream_t stream);  // 阻塞等待
cudaError_t cudaStreamQuery(cudaStream_t stream);       // 非阻塞查询
```

- `cudaStreamSynchronize`：强制阻塞主机，直到stream流执行完毕
- `cudaStreamQuery`：不阻塞主机，检查流是否执行完毕
  - 若执行完毕，返回`cudaSuccess`
  - 否则，返回`cudaErrorNotReady`

#### 3. 默认流中的顺序执行

**特性**：
- 同一个CUDA流在设备中都是顺序执行的

**示例**：
```cuda
cudaMemcpy(d_x, h_x, M, cudaMemcpyDefault);
cudaMemcpy(d_y, h_y, M, cudaMemcpyDefault);
add<<<gridSize, blockSize>>>(d_x, d_y, d_z, N);
cudaMemcpy(h_z, d_z, M, cudaMemcpyDefault);
```
从设备的角度，以上4个CUDA语句是按代码顺序执行的。

#### 4. 主机和设备计算重叠

**核函数调用的异步性**：
- 核函数启动是异步的（非阻塞）
- 主机在发出核函数调用后不会等待执行完成，而是立刻得到程序控制权

**数据传输的同步性**：
- `cudaMemcpy`函数具有隐式同步功能
- 数据传输是同步的（阻塞的）
- 主机在发出数据传输命令后会等待该命令执行完毕

**重叠实现**：
```cuda
gpu_sum<<<grid_size, block_size>>>(d_x, d_y, d_z);

// 主机函数与设备核函数重叠
cpu_sum(h_x, h_y, h_z, N / ratio);
```
当主机和设备的计算量相当时，可以达到主机函数与设备函数并发执行的效果。

#### 5. 非默认CUDA流重叠多个核函数

**要求**：
- 要实现多个核函数之间的并行必须使用多个非默认CUDA流

**指定核函数的CUDA流**：
```cuda
kernel_func<<<grid_size, block_size, 0, stream>>>(params);
```
- 第三个参数：共享内存大小（不需要时设为0）
- 第四个参数：CUDA流的id

**性能**：
- 使用多个流相对于使用一个流有加速效果
- 当流的数目超过某个阈值时，加速比就趋于饱和
- 制约因素：
  - GPU计算资源
  - GPU中能够并发执行的核函数的上限（计算能力7.5的GPU上限为128）

#### 6. 非默认CUDA流重叠核函数与数据传递

**要求**：
- 必须让核函数执行与数据传输处于不同的非默认流
- 数据传输需要使用`cudaMemcpyAsync`（异步版本）

**异步传输**：
- 由GPU的DMA（直接内存访问）实现
- 不需要主机的参与

**不可分页内存**：
- 使用异步传输时，主机内存必须是不可分页内存（固定内存）
- 防止在程序执行期间物理地址被修改
- 如果将可分页内存传递给`cudaMemcpyAsync`，则会导致同步传输

**分配不可分页内存**：
```cuda
cudaError_t cudaMallocHost(void **ptr, size_t size);
// 或
cudaError_t cudaHostAlloc(void **ptr, size_t size);

// 释放
cudaError_t cudaFreeHost(void *ptr);
```

**实现方法**：
- 将数据和相应计算操作分为若干等分
- 在每个流中发布一个CUDA操作序列

**理论加速比**：
- 如果核函数执行、主机与设备间的数据传输这3个CUDA操作能完全并行执行
- 理论上最大加速比为3

### 代码示例

**主机和设备计算重叠**：
```cuda
void timing(const real *h_x, const real *h_y, real *h_z,
            const real *d_x, const real *d_y, real *d_z,
            const int ratio, bool overlap) {
    cudaEvent_t start, stop;
    CHECK(cudaEventCreate(&start));
    CHECK(cudaEventCreate(&stop));
    CHECK(cudaEventRecord(start));
    
    if (!overlap) {
        cpu_sum(h_x, h_y, h_z, N / ratio);  // 先执行CPU计算
    }
    
    gpu_sum<<<grid_size, block_size>>>(d_x, d_y, d_z);  // GPU计算
    
    if (overlap) {
        cpu_sum(h_x, h_y, h_z, N / ratio);  // 与GPU计算重叠
    }
    
    CHECK(cudaEventRecord(stop));
    CHECK(cudaEventSynchronize(stop));
    // ... 计算时间 ...
}
```

**多个核函数并行**：
```cuda
cudaStream_t streams[MAX_NUM_STREAMS];

// 创建多个流
for (int n = 0; n < MAX_NUM_STREAMS; ++n) {
    CHECK(cudaStreamCreate(&streams[n]));
}

// 在不同流中执行核函数
for (int n = 0; n < num; ++n) {
    int offset = n * N1;
    add<<<grid_size, block_size, 0, streams[n]>>>(
        d_x + offset, d_y + offset, d_z + offset);
}

// 销毁流
for (int n = 0; n < MAX_NUM_STREAMS; ++n) {
    CHECK(cudaStreamDestroy(streams[n]));
}
```

**核函数与数据传输重叠**：
```cuda
// 分配不可分页内存
real *h_x2, *h_y2, *h_z2;
CHECK(cudaMallocHost(&h_x2, M));
CHECK(cudaMallocHost(&h_y2, M));
CHECK(cudaMallocHost(&h_z2, M));

// 创建流
cudaStream_t streams[MAX_NUM_STREAMS];
for (int i = 0; i < MAX_NUM_STREAMS; i++) {
    CHECK(cudaStreamCreate(&streams[i]));
}

// 在不同流中重叠数据传输和核函数执行
for (int i = 0; i < num; i++) {
    int offset = i * N1;
    int M1 = M / num;
    
    // 异步数据传输
    CHECK(cudaMemcpyAsync(d_x + offset, h_x2 + offset, M1, 
                          cudaMemcpyHostToDevice, streams[i]));
    CHECK(cudaMemcpyAsync(d_y + offset, h_y2 + offset, M1, 
                          cudaMemcpyHostToDevice, streams[i]));
    
    // 核函数执行
    add2<<<grid_size, block_size, 0, streams[i]>>>(
        d_x + offset, d_y + offset, d_z + offset, N1);
    
    // 异步数据传输回主机
    CHECK(cudaMemcpyAsync(h_z2 + offset, d_z + offset, M1, 
                          cudaMemcpyDeviceToHost, streams[i]));
}

// 同步所有流
for (int i = 0; i < num; i++) {
    CHECK(cudaStreamSynchronize(streams[i]));
}
```

### 体现的CUDA知识点
- CUDA流概念和创建销毁
- 默认流和非默认流
- 流同步机制
- 主机和设备计算重叠
- 多个核函数并行执行
- 核函数与数据传输重叠
- 不可分页内存（`cudaMallocHost`）
- 异步数据传输（`cudaMemcpyAsync`）

---

## 第13章：分子动力学模型

### 题目
实现分子动力学模拟，计算粒子间的相互作用力

### CUDA解决思路
- 使用半步长推进算法更新粒子位置和速度
- 将截断距离等常量放在常量内存中
- 逐步优化性能瓶颈
- 使用邻居列表减少计算量

### 具体内容

#### 1. 代码组织优化

**静态函数内联**：
- 将静态函数放在头文件中，可能被编译为内联函数
- 适用于需要被多个编译单元反复调用的函数
- 提高效率

**注意**：开发CUDA程序时，也应该尽量优化对应的C++程序

#### 2. 半步长推进算法

**问题**：
- 粒子在t+dt时刻的坐标仅依赖t时刻的坐标、速度和力
- 但是t+dt时刻的速度依赖t时刻的坐标、速度和t+dt时刻的力

**算法步骤**：
1. 以t时刻的状态计算t+dt/2时刻的速度
2. 计算t+dt时刻的坐标，同时更新t时刻的力到t+dt时刻
3. 以t+dt/2时刻的速度和t+dt时刻的力计算t+dt时刻的速度

**优势**：
- 提高数值稳定性
- 减少计算量

#### 3. 常量内存优化

**适用场景**：
- 数据量在编译期就确定且不大（明显小于4KB）
- 在核函数中仅被读取
- 一个线程束中的所有线程在某个时刻访问同一个地址

**实现方式**：
- 通过传参的方式使用常量内存
- 常量内存比全局内存高速

#### 4. 性能优化策略

**逐步分析程序的性能瓶颈**：
1. 首先确定其中最耗时的部分
2. 将其用CUDA加速，快速提高程序性能
3. 逐步优化其他部分

**平衡原则**：
- 要得到最好的加速效果，需要尽可能多的将程序中可并行的计算用CUDA加速
- 在大数情况下，需要在付出和收获间找到一个平衡点

### 体现的CUDA知识点
- 代码组织优化（静态函数内联）
- 半步长推进算法
- 常量内存的使用
- 性能优化策略
- 逐步优化方法

---

## 第14章：CUDA标准库

### 题目
介绍CUDA提供的标准库及其使用方法

### CUDA解决思路
- 使用Thrust库简化并行算法实现
- 使用cuBLAS进行线性代数运算
- 使用cuRAND生成随机数
- 使用cuSolver解决线性方程组

### 具体内容

#### 1. Thrust库

**简介**：
- 一个实现了众多基本并行算法的C++模板库
- 类似C++的标准库STL

**数据结构**：
```cuda
#include <thrust/host_vector.h>
#include <thrust/device_vector.h>

// 主机容器
thrust::host_vector<double> h_arr(12, 0.0);

// 设备容器
thrust::device_vector<double> d_arr(12, 0.0);
```

**算法**：
- 变换（Transform）
- 归约（Reduction）
- 前缀和（Prefix Sum）
- 排序与搜索（Sorting and Searching）
- 选择性复制、替换、移除、分区等重排操作

**注意**：
- Thrust函数的参数必须都来自于主机容器，或者都来自于设备容器
- `thrust::copy`除外，可以在主机和设备容器间复制
- 如果程序中大量使用了thrust库，使用设备矢量较为合适
- 如果只是偶尔使用Thrust库，则使用设备内存指针更为合适

#### 2. cuBLAS库

**简介**：
- 基本线性代数子程序（Basic Linear Algebra Subprograms）
- 提供三层功能函数：
  - 处理矢量之间的计算（如矢量之间的内积）
  - 处理矩阵和矢量之间的运算（如相乘）
  - 处理矩阵之间的运算（如相乘）

**特点**：
- CUBLAS中矩阵采用**列主序**（Column Major），即矩阵数据按列存储
- 与C/C++的行主序不同，需要注意

#### 3. cuSolver库

**简介**：
- 稠密矩阵和稀疏矩阵计算库
- 专注于一些比较高级的线性代数计算

**组成**：
- **cuSolverDN**：处理稠密矩阵线性代数计算
- **cuSolverSP**：处理稀疏矩阵线性代数计算
- **cuSolverRF**：处理稀疏矩阵分解

**特点**：
- cuSolver中矩阵同样采用**列主序**
- cuSolver库函数倾向于使用异步执行
- 为保证一个cuSolver函数的工作已完成，可以使用`cudaDeviceSynchronize()`函数进行同步

#### 4. cuRAND库

**简介**：
- 随机数生成器

**API类型**：
- **主机API**：使用设备产生伪随机数并存于设备数组，或使用主机产生伪随机数并存于主机数组
- **设备API**：在设备中生成随机数

**使用方式**：
```cuda
#include <curand.h>
// 编译时指定链接选项：-lcurand
```

#### 5. 其他CUDA库

**cuFFT**：
- 快速傅里叶变换（Fast Fourier Transform）

**cuSPARSE**：
- 稀疏矩阵运算

**cuDNN**：
- 深度神经网络（Deep Neural Network）

### 体现的CUDA知识点
- Thrust库的使用
- cuBLAS库的使用
- cuSolver库的使用
- cuRAND库的使用
- 其他CUDA库的了解
- 列主序与行主序的区别

---

## 总结

### 核心知识点体系

#### 1. 基础概念
- 主机/设备概念
- 线程组织（Grid→Block→Thread→Warp）
- 内存层次结构
- GPU架构演进

#### 2. 编程框架
- CUDA程序基本框架
- 内存管理API
- 核函数和设备函数
- 错误检测机制

#### 3. 性能优化
- **内存访问优化**：
  - 合并访问
  - 共享内存
  - 常量内存
  - 纹理内存
- **线程组织优化**：
  - 线程块大小
  - SM占有率
  - 线程利用率
- **并行优化**：
  - CUDA流
  - 异步操作
  - 主机设备重叠

#### 4. 高级特性
- 原子函数
- 线程束函数
- 协作组
- 动态并行

#### 5. 标准库
- Thrust
- cuBLAS
- cuSolver
- cuRAND

### 学习路径

1. **入门阶段**（第1-3章）：
   - GPU硬件和开发工具
   - 线程组织
   - 基本程序框架

2. **进阶阶段**（第4-6章）：
   - 错误检测
   - 性能分析
   - 内存组织

3. **优化阶段**（第7-9章）：
   - 全局内存优化
   - 共享内存优化
   - 原子函数使用

4. **高级阶段**（第10-11章）：
   - 线程束函数
   - CUDA流

5. **应用阶段**（第13-14章）：
   - 实际应用案例
   - 标准库使用

### 关键记忆点

#### 线程组织
- Grid → Block → Thread → Warp(32)
- `blockIdx`, `threadIdx`, `blockDim`, `gridDim`
- 最大线程块大小：1024
- 最大网格大小：2³¹-1（一维）

#### 内存速度排序
寄存器 > 共享内存 > L1/L2缓存 > 常量内存/纹理内存 > 全局内存

#### 性能关键因素
1. **减少数据传输**：尽量在GPU中完成计算
2. **提高算术强度**：算术操作/内存操作
3. **保证并行规模**：线程总数接近SM最大驻留线程数
4. **优化内存访问**：合并访问、避免bank冲突

#### 优化原则
- **合并访问**：相邻线程访问相邻内存地址
- **避免bank冲突**：共享内存列宽+1
- **减少分支发散**：尽量让线程束内线程执行相同分支
- **合理使用流**：重叠计算和数据传输

#### 常用API速查

**内存管理**：
- `cudaMalloc`：分配设备内存
- `cudaMemcpy`：数据传输（同步）
- `cudaMemcpyAsync`：异步数据传输
- `cudaFree`：释放设备内存
- `cudaMallocHost`：分配不可分页主机内存

**同步**：
- `cudaDeviceSynchronize`：同步所有设备操作
- `cudaStreamSynchronize`：同步指定流
- `__syncthreads()`：线程块内同步
- `__syncwarp()`：线程束内同步

**计时**：
- `cudaEventCreate`：创建事件
- `cudaEventRecord`：记录事件
- `cudaEventSynchronize`：同步事件
- `cudaEventElapsedTime`：计算时间差

**错误检测**：
- `cudaGetLastError`：获取最后一个错误
- `cudaGetErrorString`：获取错误字符串

---

*本文档基于《CUDA编程——基础与实践》（樊哲勇）和CudaSteps项目代码整理*
