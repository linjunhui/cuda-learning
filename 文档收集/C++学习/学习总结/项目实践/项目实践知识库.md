# 项目实践知识库

## 工程说明

本知识库基于 `cuda-learning` 工程中的 `每周题目/` 目录内容整理而成。该目录包含了C++和CUDA的真实项目题目，以及完成记录和实际实现。知识库会随着工程中项目题目的完成情况持续更新。

## 概述

本知识库记录每周真实项目题目的完成情况、技术要点、学习收获，作为项目经验和面试素材的重要来源。所有内容都基于工程中的实际项目题目和完成情况，反映当前的真实学习进度。

## 项目完成状态

根据工程中的实际完成记录，当前项目完成情况如下：

### CUDA入门系列

#### ✅ 入门题1：Hello CUDA - 第一个CUDA程序（已完成）

**完成时间**：已标记为完成  
**难度**：★☆☆☆☆  
**涉及技术**：CUDA安装、基本语法、设备信息查询  
**预计时间**：2-3小时  
**实际用时**：已完成

**项目目标**（来自工程中的实际README）：
1. ✅ 输出CUDA设备信息（设备名称、计算能力、显存大小等）
2. ✅ 检查CUDA运行时是否正确初始化
3. ✅ 实现简单的向量相加kernel函数

**技术实现要点**

#### 1. CUDA Kernel函数实现

根据项目要求，实现了向量相加的kernel函数：

```cuda
__global__ void vectorAdd(float *A, float *B, float *C, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        C[idx] = A[idx] + B[idx];
    }
}
```

**关键技术点**：
- 使用 `__global__` 关键字定义kernel函数
- 通过 `blockIdx.x * blockDim.x + threadIdx.x` 计算全局线程索引
- 添加边界检查 `if (idx < N)` 防止越界访问
- 每个线程处理一个数组元素，实现并行计算

#### 2. Kernel启动配置

```cuda
// 配置：grid维度 × block维度
int threadsPerBlock = 256;
int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerGrid;
vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);
```

**配置说明**：
- `threadsPerBlock = 256`：每个线程块包含256个线程（32的倍数，符合warp大小）
- `blocksPerGrid`：根据数据大小N计算所需的线程块数量
- `(N + threadsPerBlock - 1) / threadsPerBlock`：向上取整，确保所有数据都被处理

#### 3. 内存管理完整流程

根据工程中的实际实现，CUDA程序的内存管理遵循以下流程：

```
1. CPU分配内存（主机端）
   ↓
2. cudaMalloc分配设备内存（设备端）
   ↓
3. cudaMemcpy(H2D) - 主机到设备数据传输
   ↓
4. 启动kernel执行计算
   ↓
5. cudaDeviceSynchronize() - 等待GPU完成
   ↓
6. cudaMemcpy(D2H) - 设备到主机数据传输
   ↓
7. cudaFree释放设备内存
   ↓
8. CPU释放内存（主机端）
```

**实际代码示例**：

```cuda
// 1. 主机内存分配
float* h_A = (float*)malloc(N * sizeof(float));
float* h_B = (float*)malloc(N * sizeof(float));
float* h_C = (float*)malloc(N * sizeof(float));

// 2. 设备内存分配
float *d_A, *d_B, *d_C;
cudaMalloc(&d_A, N * sizeof(float));
cudaMalloc(&d_B, N * sizeof(float));
cudaMalloc(&d_C, N * sizeof(float));

// 3. 数据传输（主机到设备）
cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);
cudaMemcpy(d_B, h_B, N * sizeof(float), cudaMemcpyHostToDevice);

// 4. 启动kernel
vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);

// 5. 等待完成
cudaDeviceSynchronize();

// 6. 数据传输（设备到主机）
cudaMemcpy(h_C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

// 7. 释放设备内存
cudaFree(d_A);
cudaFree(d_B);
cudaFree(d_C);

// 8. 释放主机内存
free(h_A);
free(h_B);
free(h_C);
```

#### 4. CUDA错误检查机制

根据工程中的实际实现，使用了错误检查宏确保程序正确执行：

```cuda
#define CHECK_CUDA_ERROR(err) checkCudaError(err, __FILE__, __LINE__)

void checkCudaError(cudaError_t err, const char* file, int line) {
    if (err != cudaSuccess) {
        fprintf(stderr, "CUDA error at %s:%d: %s\n", 
                file, line, cudaGetErrorString(err));
        exit(1);
    }
}

// 使用示例
CHECK_CUDA_ERROR(cudaMalloc(&d_ptr, size));
CHECK_CUDA_ERROR(cudaGetLastError());  // 检查kernel启动错误
CHECK_CUDA_ERROR(cudaDeviceSynchronize());  // 等待kernel完成
```

**错误检查的重要性**：
- CUDA操作可能失败但不报错，需要显式检查
- kernel启动错误需要调用 `cudaGetLastError()` 检查
- 同步操作可能失败，需要检查返回值

#### 5. 设备信息查询

根据项目要求，实现了完整的设备信息查询功能：

```cuda
void printDeviceInfo() {
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);
    
    for (int i = 0; i < deviceCount; i++) {
        cudaDeviceProp prop;
        cudaGetDeviceProperties(&prop, i);
        
        printf("========================================\n");
        printf("设备 %d 详细信息\n", i);
        printf("========================================\n");
        printf("设备名称:          %s\n", prop.name);
        printf("计算能力:          %d.%d\n", prop.major, prop.minor);
        printf("显存大小:          %.2f GB (%zu MB)\n", 
               prop.totalGlobalMem / (1024.0 * 1024.0 * 1024.0),
               prop.totalGlobalMem / (1024 * 1024));
        printf("多处理器数量:      %d\n", prop.multiProcessorCount);
        printf("每块最大线程数:    %d\n", prop.maxThreadsPerBlock);
        printf("共享内存 per Block: %zu bytes\n", prop.sharedMemPerBlock);
        printf("Warp Size:         %d\n", prop.warpSize);
    }
}
```

**实际设备信息**（来自项目运行结果）：
- GPU型号：NVIDIA GeForce GTX 1660 SUPER
- 计算能力：7.5
- 显存大小：6.00 GB (6144 MB)
- 多处理器数量：22
- 每块最大线程数：1024
- Warp Size：32

#### 6. 项目结构

根据工程中的实际目录结构：

```
proj1_hello_world/
├── CMakeLists.txt           # 构建配置文件
├── README.md                # 项目说明文档
├── include/
│   └── cuda_utils.h         # CUDA工具函数头文件
└── src/
    ├── main.cu              # 主程序（向量相加kernel实现）
    └── device_info.cu       # 设备信息查询功能
```

**文件说明**：
- `CMakeLists.txt`：配置CUDA编译选项和链接库
- `cuda_utils.h`：封装常用的CUDA操作和错误检查
- `main.cu`：实现向量相加的主要逻辑
- `device_info.cu`：设备信息查询的实现

**验收标准**（全部满足）：
- ✅ 程序能够成功编译和运行
- ✅ 正确输出设备信息
- ✅ 向量相加结果正确（与CPU结果验证一致）
- ✅ 正确释放所有内存资源

**学习收获**：

1. **CUDA基本编程模型**：
   - 理解了host/device分离的概念
   - 掌握了kernel函数的定义和调用
   - 理解了线程组织（grid、block、thread）的关系

2. **CUDA内存管理**：
   - 熟悉了设备内存分配和释放流程
   - 掌握了主机-设备数据传输方法
   - 理解了不同内存类型的特点

3. **CUDA线程模型**：
   - 理解了线程索引计算的方法
   - 掌握了kernel启动配置的计算
   - 理解了边界检查的重要性

4. **错误处理**：
   - 学会了CUDA错误检查的方法
   - 理解了错误检查的重要性
   - 掌握了调试CUDA程序的技巧

5. **工程实践**：
   - 熟悉了CMake构建CUDA项目
   - 学会了代码组织和模块化
   - 理解了文档编写的重要性

**面试要点总结**：

1. **项目背景**：
   - 第一个CUDA程序，学习GPU并行计算的基础
   - 实现了向量相加这一经典并行计算任务

2. **技术难点**：
   - 线程索引计算：`blockIdx.x * blockDim.x + threadIdx.x`
   - 内存管理：理解主机和设备内存分离
   - 错误处理：CUDA错误可能静默失败

3. **性能考虑**：
   - 线程块大小选择：256（32的倍数）
   - 内存访问模式：连续访问，避免随机访问
   - 边界检查：确保不越界访问

4. **优化方向**：
   - 使用共享内存减少全局内存访问
   - 优化内存访问模式，实现合并访问
   - 使用CUDA事件进行精确性能测量

#### ⬜ 入门题2：向量加法性能对比（计划中）

**难度**：★☆☆☆☆  
**涉及技术**：CUDA线程模型、性能分析、内存带宽  
**预计时间**：3-4小时

**项目目标**（来自工程README）：
- 实现CPU串行版本的向量加法
- 实现GPU并行版本的向量加法
- 测试不同数据量下的性能
- 分析内存带宽利用率

**技术要点**：
- 理解CUDA线程和线程块概念
- 掌握kernel启动配置（grid、block）
- 使用事件计算执行时间
- 理解全局内存访问模式

**预期学习收获**：
- 对比CPU和GPU的性能差异
- 理解GPU并行计算的优势
- 掌握性能分析方法
- 学会优化内存访问模式

#### ⬜ 入门题3：数组元素平方计算（计划中）

**难度**：★☆☆☆☆  
**涉及技术**：CUDA内核函数、数组操作、索引计算  
**预计时间**：2-3小时

**项目目标**：
- 实现GPU kernel计算数组元素的平方
- 支持任意大小的数组
- 实现多种索引方式（1D、2D、3D）
- 添加边界检查机制

**技术要点**：
- 理解线程索引计算
- 掌握多维数组的访问模式
- 学会处理非整数倍的数组大小
- 熟悉CUDA错误检查

#### ⬜ 入门题4：简单的归约运算（求和）（计划中）

**难度**：★★☆☆☆  
**涉及技术**：共享内存、线程同步、归约算法  
**预计时间**：4-6小时

**项目目标**：
- 实现GPU版本的数组求和归约
- 使用全局内存的朴素实现
- 使用共享内存的优化版本
- 实现树形归约算法
- 对比不同实现的性能

**技术要点**：
- 理解共享内存特性
- 掌握同步函数（__syncthreads）
- 学会避免共享内存库冲突
- 理解归约优化技巧

#### ⬜ 入门题5：设备内存管理工具（计划中）

**难度**：★★☆☆☆  
**涉及技术**：内存管理、CUDA Runtime API、错误处理  
**预计时间**：3-4小时

**项目目标**：
- 开发一个简单的CUDA内存管理工具类
- 封装设备内存分配和释放
- 提供主机-设备数据传输接口
- 添加内存使用统计功能
- 实现异常安全的内存管理

**技术要点**：
- 熟练使用cudaMalloc、cudaMemcpy等API
- 理解不同内存类型（host、device、unified）
- 实现RAII风格的内存管理
- 提供详细的错误信息

### C++题目系列

根据工程中的实际记录，所有C++题目目前都处于未开始状态：

#### ⬜ 第1周：高性能字符串处理库（未开始）

**难度**：★★★☆☆  
**涉及技术**：内存管理、性能优化、STL、字符串处理  
**预计时间**：8-12小时

**核心需求**：
1. 基础字符串操作：拼接、分割、查找、替换
2. 内存管理优化：避免频繁内存分配，使用内存池
3. 多编码支持：UTF-8、UTF-16等编码格式
4. 高性能算法：字符串比较、排序算法优化

**技术实现要点**：

**内存池设计**：
- 预分配策略：启动时预分配大块内存
- 分层管理：不同大小的字符串使用不同的内存块
- 回收机制：实现内存块的回收和重用
- 线程安全：使用无锁或低锁的并发访问

**字符串类设计**：
- 小字符串优化：短字符串直接存储在对象内部
- 引用计数：长字符串使用引用计数共享内存
- 移动语义：支持高效的字符串转移
- 异常安全：提供强异常安全保证

**字符串操作优化**：
- 拼接操作：预分配策略、移动语义、批量操作
- 查找算法：Boyer-Moore算法、多模式匹配、并行搜索
- 分割操作：延迟分割、视图模式、迭代器模式

#### ⬜ 第2-5周：其他C++项目（未开始）

- 第2周：线程安全的对象池
- 第3周：基于模板的序列化框架
- 第4周：内存泄漏检测工具
- 第5周：高性能JSON解析器

## 项目完成统计

### CUDA项目
- **已完成**：1/5（入门题1：Hello CUDA）
- **计划中**：4/5

### C++项目
- **已完成**：0/5
- **计划中**：5/5

### 总计
- **已完成**：1/10
- **完成率**：10%

## 项目经验总结

### 技术栈积累

**CUDA技能**：
- ✅ CUDA基本编程模型（host/device、kernel、线程组织）
- ✅ CUDA内存管理（设备内存分配、数据传输）
- ✅ CUDA线程模型（grid、block、thread的关系）
- ✅ 设备信息查询和错误处理
- ⬜ 性能分析和优化（待学习）
- ⬜ 共享内存使用（待学习）
- ⬜ CUDA库使用（待学习）

**工程能力**：
- ✅ CMake构建CUDA项目
- ✅ 代码组织和模块化
- ✅ 文档编写
- ✅ 错误处理和调试
- ⬜ 性能分析工具使用（待学习）
- ⬜ 版本控制和协作（待学习）

### 面试素材准备

**已完成项目（Hello CUDA）**：

1. **项目背景和目标**：
   - 学习CUDA编程的第一步
   - 实现向量相加这一经典并行计算任务
   - 掌握CUDA基本编程模型和内存管理

2. **技术难点和解决方案**：
   - **难点1**：理解主机和设备内存分离 → 通过实践理解内存传输的必要性
   - **难点2**：线程索引计算 → 通过公式和示例代码理解计算方式
   - **难点3**：错误处理 → 实现错误检查宏确保程序正确执行

3. **性能数据和优化成果**：
   - 实现了基本的GPU并行计算
   - 理解了GPU并行计算的基本原理
   - 掌握了性能优化的基本思路（内存访问模式、线程配置）

4. **遇到的问题和解决方法**：
   - **问题1**：CUDA错误静默失败 → 添加错误检查机制
   - **问题2**：边界检查不足 → 添加条件判断防止越界
   - **问题3**：内存管理混乱 → 遵循标准的内存管理流程

5. **项目收获和思考**：
   - 深入理解了GPU并行计算的本质
   - 掌握了CUDA编程的基本模式
   - 为后续复杂项目打下基础

### 下一步计划

1. **短期计划**（1-2周）：
   - 完成CUDA入门系列剩余4题
   - 深入学习共享内存和性能优化
   - 掌握CUDA性能分析工具

2. **中期计划**（1-2个月）：
   - 开始C++项目实践
   - 完成CUDA进阶系列项目
   - 积累更多项目经验

3. **长期计划**（3-6个月）：
   - 完成所有计划项目
   - 深入研究性能优化技术
   - 准备综合项目实践

---

**最后更新**：根据工程实际完成情况更新  
**知识库用途**：项目经验记录、面试准备、技术积累、学习指导
