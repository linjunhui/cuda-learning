# 第7周：项目实践

## 学习目标

综合运用所学知识，完成完整的CUDA项目，包括GPU工程应用开发、性能优化实践、系统集成和部署。

## 学习内容

### 1. 项目规划和管理

#### 1.1 项目需求分析
```cuda
// 项目需求分析示例
class ProjectRequirements {
private:
    std::string projectName;
    std::vector<std::string> requirements;
    std::vector<std::string> constraints;
    
public:
    ProjectRequirements(const std::string& name) : projectName(name) {}
    
    void addRequirement(const std::string& req) {
        requirements.push_back(req);
    }
    
    void addConstraint(const std::string& constraint) {
        constraints.push_back(constraint);
    }
    
    void printRequirements() {
        printf("Project: %s\n", projectName.c_str());
        printf("Requirements:\n");
        for (const auto& req : requirements) {
            printf("  - %s\n", req.c_str());
        }
        printf("Constraints:\n");
        for (const auto& constraint : constraints) {
            printf("  - %s\n", constraint.c_str());
        }
    }
};

// 使用示例
void analyzeProjectRequirements() {
    ProjectRequirements req("GPU Image Processing System");
    
    req.addRequirement("Support multiple image formats (PNG, JPEG, BMP)");
    req.addRequirement("Implement real-time image filtering");
    req.addRequirement("Support batch processing");
    req.addRequirement("Provide CPU fallback");
    req.addRequirement("Achieve 10x speedup over CPU implementation");
    
    req.addConstraint("Must run on CUDA 11.0+");
    req.addConstraint("Memory usage < 2GB");
    req.addConstraint("Processing time < 100ms per image");
    
    req.printRequirements();
}
```

#### 1.2 项目架构设计
```cuda
// 项目架构设计
class ProjectArchitecture {
private:
    std::string architectureName;
    std::vector<std::string> components;
    std::map<std::string, std::string> interfaces;
    
public:
    ProjectArchitecture(const std::string& name) : architectureName(name) {}
    
    void addComponent(const std::string& component) {
        components.push_back(component);
    }
    
    void addInterface(const std::string& component, const std::string& interface) {
        interfaces[component] = interface;
    }
    
    void printArchitecture() {
        printf("Architecture: %s\n", architectureName.c_str());
        printf("Components:\n");
        for (const auto& component : components) {
            printf("  - %s\n", component.c_str());
            if (interfaces.find(component) != interfaces.end()) {
                printf("    Interface: %s\n", interfaces[component].c_str());
            }
        }
    }
};

// 使用示例
void designProjectArchitecture() {
    ProjectArchitecture arch("GPU Image Processing Architecture");
    
    arch.addComponent("Image Loader");
    arch.addComponent("GPU Memory Manager");
    arch.addComponent("CUDA Kernel Manager");
    arch.addComponent("Image Processor");
    arch.addComponent("Result Exporter");
    
    arch.addInterface("Image Loader", "Load images from disk");
    arch.addInterface("GPU Memory Manager", "Manage GPU memory allocation");
    arch.addInterface("CUDA Kernel Manager", "Manage CUDA kernels");
    arch.addInterface("Image Processor", "Process images on GPU");
    arch.addInterface("Result Exporter", "Export processed images");
    
    arch.printArchitecture();
}
```

### 2. 系统实现

#### 2.1 核心系统类
```cuda
// 核心系统类
class GPUImageProcessor {
private:
    int deviceCount;
    int currentDevice;
    cudaStream_t* streams;
    int streamCount;
    
public:
    GPUImageProcessor() {
        cudaGetDeviceCount(&deviceCount);
        currentDevice = 0;
        streamCount = 4;
        
        streams = new cudaStream_t[streamCount];
        for (int i = 0; i < streamCount; i++) {
            cudaStreamCreate(&streams[i]);
        }
        
        printf("GPU Image Processor initialized with %d devices\n", deviceCount);
    }
    
    ~GPUImageProcessor() {
        for (int i = 0; i < streamCount; i++) {
            cudaStreamDestroy(streams[i]);
        }
        delete[] streams;
    }
    
    void setDevice(int device) {
        if (device >= 0 && device < deviceCount) {
            currentDevice = device;
            cudaSetDevice(device);
        }
    }
    
    cudaStream_t getStream(int index) {
        return streams[index % streamCount];
    }
    
    int getDeviceCount() const {
        return deviceCount;
    }
    
    int getCurrentDevice() const {
        return currentDevice;
    }
};
```

#### 2.2 图像处理模块
```cuda
// 图像处理模块
class ImageProcessingModule {
private:
    GPUImageProcessor* processor;
    
public:
    ImageProcessingModule(GPUImageProcessor* proc) : processor(proc) {}
    
    void processImage(cv::Mat& input, cv::Mat& output, const std::string& operation) {
        if (operation == "gaussian") {
            gaussianFilter(input, output);
        } else if (operation == "sobel") {
            sobelFilter(input, output);
        } else if (operation == "canny") {
            cannyEdgeDetection(input, output);
        } else {
            printf("Unknown operation: %s\n", operation.c_str());
        }
    }
    
private:
    void gaussianFilter(cv::Mat& input, cv::Mat& output) {
        // GPU高斯滤波实现
        float* d_input, *d_output;
        size_t size = input.rows * input.cols * sizeof(float);
        
        cudaMalloc(&d_input, size);
        cudaMalloc(&d_output, size);
        
        // 转换为浮点
        cv::Mat inputFloat;
        input.convertTo(inputFloat, CV_32F);
        
        cudaMemcpy(d_input, inputFloat.data, size, cudaMemcpyHostToDevice);
        
        // 启动高斯滤波内核
        dim3 blockSize(16, 16);
        dim3 gridSize((input.cols + blockSize.x - 1) / blockSize.x,
                      (input.rows + blockSize.y - 1) / blockSize.y);
        
        gaussianFilterKernel<<<gridSize, blockSize>>>(d_input, d_output, input.cols, input.rows);
        
        cudaMemcpy(output.data, d_output, size, cudaMemcpyDeviceToHost);
        
        cudaFree(d_input);
        cudaFree(d_output);
    }
    
    void sobelFilter(cv::Mat& input, cv::Mat& output) {
        // GPU Sobel滤波实现
        float* d_input, *d_output;
        size_t size = input.rows * input.cols * sizeof(float);
        
        cudaMalloc(&d_input, size);
        cudaMalloc(&d_output, size);
        
        cv::Mat inputFloat;
        input.convertTo(inputFloat, CV_32F);
        
        cudaMemcpy(d_input, inputFloat.data, size, cudaMemcpyHostToDevice);
        
        dim3 blockSize(16, 16);
        dim3 gridSize((input.cols + blockSize.x - 1) / blockSize.x,
                      (input.rows + blockSize.y - 1) / blockSize.y);
        
        sobelFilterKernel<<<gridSize, blockSize>>>(d_input, d_output, input.cols, input.rows);
        
        cudaMemcpy(output.data, d_output, size, cudaMemcpyDeviceToHost);
        
        cudaFree(d_input);
        cudaFree(d_output);
    }
    
    void cannyEdgeDetection(cv::Mat& input, cv::Mat& output) {
        // GPU Canny边缘检测实现
        float* d_input, *d_output;
        size_t size = input.rows * input.cols * sizeof(float);
        
        cudaMalloc(&d_input, size);
        cudaMalloc(&d_output, size);
        
        cv::Mat inputFloat;
        input.convertTo(inputFloat, CV_32F);
        
        cudaMemcpy(d_input, inputFloat.data, size, cudaMemcpyHostToDevice);
        
        dim3 blockSize(16, 16);
        dim3 gridSize((input.cols + blockSize.x - 1) / blockSize.x,
                      (input.rows + blockSize.y - 1) / blockSize.y);
        
        cannyEdgeDetectionKernel<<<gridSize, blockSize>>>(d_input, d_output, input.cols, input.rows);
        
        cudaMemcpy(output.data, d_output, size, cudaMemcpyDeviceToHost);
        
        cudaFree(d_input);
        cudaFree(d_output);
    }
};
```

#### 2.3 性能监控模块
```cuda
// 性能监控模块
class PerformanceMonitor {
private:
    std::map<std::string, float> metrics;
    cudaEvent_t start, stop;
    
public:
    PerformanceMonitor() {
        cudaEventCreate(&start);
        cudaEventCreate(&stop);
    }
    
    ~PerformanceMonitor() {
        cudaEventDestroy(start);
        cudaEventDestroy(stop);
    }
    
    void startTimer() {
        cudaEventRecord(start);
    }
    
    void stopTimer() {
        cudaEventRecord(stop);
        cudaEventSynchronize(stop);
    }
    
    float getElapsedTime() {
        float milliseconds = 0;
        cudaEventElapsedTime(&milliseconds, start, stop);
        return milliseconds;
    }
    
    void recordMetric(const std::string& name, float value) {
        metrics[name] = value;
    }
    
    void printMetrics() {
        printf("Performance Metrics:\n");
        for (const auto& metric : metrics) {
            printf("  %s: %.2f\n", metric.first.c_str(), metric.second);
        }
    }
    
    void saveMetrics(const std::string& filename) {
        std::ofstream file(filename);
        if (file.is_open()) {
            for (const auto& metric : metrics) {
                file << metric.first << "," << metric.second << "\n";
            }
            file.close();
        }
    }
};
```

### 3. 测试和部署

#### 3.1 单元测试
```cuda
// 单元测试框架
class UnitTest {
private:
    std::string testName;
    bool passed;
    
public:
    UnitTest(const std::string& name) : testName(name), passed(false) {}
    
    void assertTrue(bool condition, const std::string& message = "") {
        if (condition) {
            passed = true;
            printf("✓ %s passed\n", testName.c_str());
        } else {
            printf("✗ %s failed: %s\n", testName.c_str(), message.c_str());
        }
    }
    
    void assertFalse(bool condition, const std::string& message = "") {
        assertTrue(!condition, message);
    }
    
    void assertEqual(float expected, float actual, float tolerance = 1e-6) {
        bool condition = abs(expected - actual) < tolerance;
        assertTrue(condition, "Expected: " + std::to_string(expected) + 
                  ", Actual: " + std::to_string(actual));
    }
    
    bool getResult() const {
        return passed;
    }
};

// 测试用例
void runUnitTests() {
    printf("Running Unit Tests...\n");
    
    // 测试GPU内存分配
    UnitTest test1("GPU Memory Allocation");
    float* d_data;
    cudaError_t err = cudaMalloc(&d_data, 1024 * sizeof(float));
    test1.assertTrue(err == cudaSuccess, "GPU memory allocation failed");
    cudaFree(d_data);
    
    // 测试内核函数
    UnitTest test2("Kernel Function");
    float* h_data = new float[1024];
    float* d_data;
    
    for (int i = 0; i < 1024; i++) {
        h_data[i] = i;
    }
    
    cudaMalloc(&d_data, 1024 * sizeof(float));
    cudaMemcpy(d_data, h_data, 1024 * sizeof(float), cudaMemcpyHostToDevice);
    
    simpleKernel<<<4, 256>>>(d_data, 1024);
    
    cudaMemcpy(h_data, d_data, 1024 * sizeof(float), cudaMemcpyDeviceToHost);
    
    test2.assertEqual(0.0f, h_data[0], 1e-6);
    test2.assertEqual(2.0f, h_data[1], 1e-6);
    
    cudaFree(d_data);
    delete[] h_data;
    
    printf("Unit tests completed\n");
}

__global__ void simpleKernel(float* data, int size) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (tid < size) {
        data[tid] = data[tid] * 2.0f;
    }
}
```

#### 3.2 集成测试
```cuda
// 集成测试
class IntegrationTest {
private:
    GPUImageProcessor* processor;
    ImageProcessingModule* module;
    PerformanceMonitor* monitor;
    
public:
    IntegrationTest() {
        processor = new GPUImageProcessor();
        module = new ImageProcessingModule(processor);
        monitor = new PerformanceMonitor();
    }
    
    ~IntegrationTest() {
        delete processor;
        delete module;
        delete monitor;
    }
    
    void runIntegrationTests() {
        printf("Running Integration Tests...\n");
        
        // 测试图像处理流程
        testImageProcessingPipeline();
        
        // 测试性能
        testPerformance();
        
        // 测试多GPU
        testMultiGPU();
        
        printf("Integration tests completed\n");
    }
    
private:
    void testImageProcessingPipeline() {
        printf("Testing image processing pipeline...\n");
        
        // 创建测试图像
        cv::Mat input = cv::Mat::ones(512, 512, CV_8UC1) * 128;
        cv::Mat output;
        
        // 测试高斯滤波
        monitor->startTimer();
        module->processImage(input, output, "gaussian");
        monitor->stopTimer();
        
        float gaussianTime = monitor->getElapsedTime();
        monitor->recordMetric("Gaussian Filter Time", gaussianTime);
        
        printf("Gaussian filter completed in %.2f ms\n", gaussianTime);
    }
    
    void testPerformance() {
        printf("Testing performance...\n");
        
        cv::Mat input = cv::Mat::ones(1024, 1024, CV_8UC1) * 128;
        cv::Mat output;
        
        // 测试不同操作性能
        std::vector<std::string> operations = {"gaussian", "sobel", "canny"};
        
        for (const auto& op : operations) {
            monitor->startTimer();
            module->processImage(input, output, op);
            monitor->stopTimer();
            
            float time = monitor->getElapsedTime();
            monitor->recordMetric(op + " Time", time);
            
            printf("%s completed in %.2f ms\n", op.c_str(), time);
        }
    }
    
    void testMultiGPU() {
        printf("Testing multi-GPU...\n");
        
        int deviceCount = processor->getDeviceCount();
        
        for (int i = 0; i < deviceCount; i++) {
            processor->setDevice(i);
            
            cv::Mat input = cv::Mat::ones(512, 512, CV_8UC1) * 128;
            cv::Mat output;
            
            monitor->startTimer();
            module->processImage(input, output, "gaussian");
            monitor->stopTimer();
            
            float time = monitor->getElapsedTime();
            monitor->recordMetric("GPU " + std::to_string(i) + " Time", time);
            
            printf("GPU %d completed in %.2f ms\n", i, time);
        }
    }
};
```

#### 3.3 部署配置
```cuda
// 部署配置
class DeploymentConfig {
private:
    std::map<std::string, std::string> config;
    
public:
    DeploymentConfig() {
        // 默认配置
        config["cuda_version"] = "11.0";
        config["gpu_memory"] = "2GB";
        config["max_threads"] = "1024";
        config["stream_count"] = "4";
        config["debug_mode"] = "false";
    }
    
    void loadConfig(const std::string& filename) {
        std::ifstream file(filename);
        if (file.is_open()) {
            std::string line;
            while (std::getline(file, line)) {
                size_t pos = line.find('=');
                if (pos != std::string::npos) {
                    std::string key = line.substr(0, pos);
                    std::string value = line.substr(pos + 1);
                    config[key] = value;
                }
            }
            file.close();
        }
    }
    
    void saveConfig(const std::string& filename) {
        std::ofstream file(filename);
        if (file.is_open()) {
            for (const auto& pair : config) {
                file << pair.first << "=" << pair.second << "\n";
            }
            file.close();
        }
    }
    
    std::string getConfig(const std::string& key) {
        return config[key];
    }
    
    void setConfig(const std::string& key, const std::string& value) {
        config[key] = value;
    }
    
    void printConfig() {
        printf("Deployment Configuration:\n");
        for (const auto& pair : config) {
            printf("  %s = %s\n", pair.first.c_str(), pair.second.c_str());
        }
    }
};
```

## 实践项目

### 项目1：GPU图像处理系统
实现完整的GPU图像处理系统，包括多种滤波算法和性能优化。

### 项目2：科学计算应用
实现GPU加速的科学计算应用，包括数值计算和数据分析。

### 项目3：机器学习加速
实现GPU加速的机器学习算法，包括神经网络和深度学习。

## 每日学习任务

### 第1天：项目规划
- 学习项目需求分析
- 掌握项目架构设计
- 理解项目管理方法

### 第2天：系统实现
- 学习核心系统实现
- 掌握模块化设计
- 理解系统集成

### 第3天：性能优化
- 学习性能监控
- 掌握性能优化技术
- 理解性能调优

### 第4天：测试框架
- 学习单元测试
- 掌握集成测试
- 理解测试驱动开发

### 第5天：部署配置
- 学习部署配置
- 掌握系统部署
- 理解运维管理

### 第6天：项目实践
- 实现完整项目
- 综合运用技术
- 完成项目交付

### 第7天：项目总结
- 总结项目经验
- 分析项目成果
- 准备面试展示

## 检查点

### 第7周结束时的能力要求
- [ ] 能够完成项目规划
- [ ] 掌握系统实现方法
- [ ] 能够进行性能优化
- [ ] 掌握测试和部署
- [ ] 理解项目管理
- [ ] 能够独立完成项目
- [ ] 完成项目1-3
- [ ] 具备项目实践能力

## 常见问题解答

### Q: 项目如何规划？
A: 明确需求，设计架构，分解任务，制定计划，跟踪进度。

### Q: 系统如何实现？
A: 模块化设计，接口定义，逐步实现，集成测试。

### Q: 性能如何优化？
A: 性能监控，瓶颈分析，优化策略，效果验证。

### Q: 项目如何部署？
A: 环境配置，依赖管理，部署脚本，监控运维。

---

**学习时间**：第7周  
**预计完成时间**：2024-03-29























