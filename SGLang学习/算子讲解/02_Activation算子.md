# Activation ç®—å­è¯¦è§£ï¼ˆSiLU / GELUï¼‰

## ğŸ“– ç®—å­æ¦‚è¿°

**Activationï¼ˆæ¿€æ´»å‡½æ•°ï¼‰** æ˜¯ç¥ç»ç½‘ç»œä¸­æœ€åŸºç¡€çš„ç®—å­ä¹‹ä¸€ã€‚åœ¨ LLM ä¸­ï¼Œæœ€å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ï¼š

- **SiLU (Swish)**ï¼š`silu(x) = x / (1 + exp(-x))`
- **GELU**ï¼š`gelu(x) = x * 0.5 * (1 + erf(x / âˆš2))`
- **GELU-Tanh**ï¼šGELU çš„è¿‘ä¼¼å®ç°
- **GELU-Quick**ï¼š`gelu_quick(x) = x * sigmoid(1.702 * x)`

**ç”¨é€”**ï¼š
- Transformer ä¸­çš„ FFNï¼ˆå‰é¦ˆç½‘ç»œï¼‰
- æ¯ä¸ª token çš„æ¿€æ´»å‡½æ•°è®¡ç®—
- å¤§é‡å¹¶è¡Œè®¡ç®—ï¼Œé€‚åˆ GPU

**ç‰¹ç‚¹**ï¼š
- é€å…ƒç´ æ“ä½œï¼ˆelement-wiseï¼‰
- æ¯ä¸ªå…ƒç´ ç‹¬ç«‹è®¡ç®—
- è®¡ç®—ç®€å•ä½†è®¡ç®—é‡å¤§

---

## ğŸ”¢ å…¬å¼ä¸ç®—æ³•

### 1. SiLU (Swish) æ¿€æ´»å‡½æ•°

#### æ•°å­¦å…¬å¼

```
SiLU(x) = x / (1 + exp(-x))
```

**ç­‰ä»·å½¢å¼**ï¼š
```
SiLU(x) = x * sigmoid(x)
SiLU(x) = x * (1 / (1 + exp(-x)))
```

#### å‡½æ•°å›¾åƒ

```
      |
   y  |      /
      |     /
  0.5 |----/-------
      |   /
      |  /
      | /
  0.0 +----------------> x
      -3  -2  -1   0   1   2   3
```

**ç‰¹ç‚¹**ï¼š
- å¹³æ»‘ã€éå•è°ƒ
- åœ¨è´Ÿå€¼åŒºåŸŸä¹Ÿæœ‰è¾“å‡ºï¼ˆä¸ ReLU ä¸åŒï¼‰
- é›¶å€¼å¤„å¯¼æ•°ä¸º 0.5

#### å¯¼æ•°

```
d/dx SiLU(x) = sigmoid(x) * (1 + x * (1 - sigmoid(x)))
            = sigmoid(x) + x * sigmoid(x) * (1 - sigmoid(x))
```

### 2. GELU æ¿€æ´»å‡½æ•°

#### æ•°å­¦å…¬å¼

```
GELU(x) = x * 0.5 * (1 + erf(x / âˆš2))
```

å…¶ä¸­ `erf` æ˜¯è¯¯å·®å‡½æ•°ï¼š
```
erf(x) = (2/âˆšÏ€) âˆ«[0 to x] e^(-tÂ²) dt
```

#### è¿‘ä¼¼å…¬å¼

**GELU-Tanh**ï¼š
```
GELU(x) â‰ˆ 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))
```

**GELU-Quick**ï¼š
```
GELU(x) â‰ˆ x * sigmoid(1.702 * x)
```

### 3. SiLU and Mulï¼ˆèåˆæ“ä½œï¼‰

åœ¨ LLM ä¸­ï¼Œç»å¸¸éœ€è¦è®¡ç®—ï¼š
```
out = silu(x[:d]) * x[d:]
```

**å«ä¹‰**ï¼š
- è¾“å…¥æ•°ç»„å‰ä¸€åŠï¼šåº”ç”¨ SiLU
- è¾“å…¥æ•°ç»„åä¸€åŠï¼šä¿æŒä¸å˜
- ç»“æœï¼šé€å…ƒç´ ç›¸ä¹˜

**ç”¨é€”**ï¼š
- **SwiGLU** æ¿€æ´»å‡½æ•°
- å‡å°‘ kernel å¯åŠ¨æ¬¡æ•°
- æé«˜ç¼“å­˜åˆ©ç”¨ç‡

---

## ğŸ§  ç®—æ³•åŸç†

### åŸºæœ¬ç®—æ³•

å¯¹äºé€å…ƒç´ æ¿€æ´»å‡½æ•°ï¼š

```
for each element x in input:
    output = activation_function(x)
```

**å¹¶è¡ŒåŒ–**ï¼š
- æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ªæˆ–å¤šä¸ªå…ƒç´ 
- å…ƒç´ é—´æ— ä¾èµ–ï¼Œå®Œå…¨å¹¶è¡Œ
- ä½¿ç”¨ Grid-Stride Loop å¤„ç†ä»»æ„å¤§å°

### æ•°å€¼ç¨³å®šæ€§

**é—®é¢˜**ï¼šè®¡ç®— `exp(-x)` æ—¶ï¼Œå¦‚æœ `x` å¾ˆå¤§ï¼ˆå¦‚ `x > 88`ï¼‰ï¼Œ`exp(-x)` ä¼šä¸‹æº¢åˆ° 0ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ `expf`ï¼ˆå•ç²¾åº¦ç‰ˆæœ¬ï¼‰
- å¯¹äº `half` ç±»å‹ï¼Œå…ˆè½¬ `float` è®¡ç®—ï¼Œå†è½¬å› `half`
- é¿å…ç²¾åº¦æŸå¤±

### ç±»å‹è½¬æ¢æŠ€å·§

```cpp
float f32_val = detail::to_f32(x);  // è½¬ä¸º float32 è®¡ç®—
float result = f32_val / (1.0f + expf(-f32_val));
return detail::from_f32<T>(result);  // è½¬å›åŸç±»å‹
```

**ä¸ºä»€ä¹ˆè¿™æ ·ï¼Ÿ**
- **ç²¾åº¦**ï¼š`float32` è®¡ç®—ç²¾åº¦æ›´é«˜
- **èŒƒå›´**ï¼š`float32` çš„æ•°å€¼èŒƒå›´æ›´å¤§
- **ç¡¬ä»¶**ï¼šç°ä»£ GPU çš„ `float32` è¿ç®—æ›´å¿«

---

## ğŸ’» ä»£ç å®ç°

### æºç ä½ç½®

`SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu`

### 1. SiLU å‡½æ•°å®ç°

```56:60:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
template <typename T>
__device__ __forceinline__ T silu(const T& x) {
  float f32_val = detail::to_f32(x);
  return detail::from_f32<T>(f32_val / (1.0f + expf(-f32_val)));
}
```

#### ä»£ç è§£æ

**ç¬¬ 1 è¡Œï¼šæ¨¡æ¿å‡½æ•°**
```cpp
template <typename T>
__device__ __forceinline__ T silu(const T& x)
```
- **æ¨¡æ¿**ï¼šæ”¯æŒå¤šç§ç±»å‹ï¼ˆ`half`ã€`float`ã€`bfloat16`ï¼‰
- **`__device__`**ï¼šåœ¨ GPU ä¸Šæ‰§è¡Œ
- **`__forceinline__`**ï¼šå¼ºåˆ¶å†…è”ï¼Œå‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€

**ç¬¬ 2 è¡Œï¼šç±»å‹è½¬æ¢**
```cpp
float f32_val = detail::to_f32(x);
```
- å°†è¾“å…¥è½¬ä¸º `float32`
- `detail::to_f32` å¤„ç†ä¸åŒç±»å‹çš„è½¬æ¢

**ç¬¬ 3 è¡Œï¼šè®¡ç®—**
```cpp
return detail::from_f32<T>(f32_val / (1.0f + expf(-f32_val)));
```
- **`expf(-f32_val)`**ï¼šè®¡ç®— `exp(-x)`ï¼Œä½¿ç”¨å•ç²¾åº¦ç‰ˆæœ¬
- **`1.0f + ...`**ï¼šè®¡ç®— `1 + exp(-x)`
- **`f32_val / ...`**ï¼šè®¡ç®— `x / (1 + exp(-x))`
- **`detail::from_f32<T>`**ï¼šè½¬å›åŸç±»å‹

### 2. GELU å‡½æ•°å®ç°

```62:67:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
template <typename T>
__device__ __forceinline__ T gelu(const T& x) {
  constexpr float kAlpha = M_SQRT1_2;
  float f32_val = detail::to_f32(x);
  return detail::from_f32<T>(f32_val * (0.5f * (1.0f + erf(f32_val * kAlpha))));
}
```

**å…³é”®ç‚¹**ï¼š
- **`M_SQRT1_2`**ï¼š`1/âˆš2 = 0.7071067811865476`
- **`erf`**ï¼šè¯¯å·®å‡½æ•°ï¼ŒCUDA å†…ç½®å‡½æ•°
- å…¬å¼ï¼š`x * 0.5 * (1 + erf(x / âˆš2))`

### 3. GELU-Tanh å®ç°ï¼ˆæ›´å¿«ï¼‰

```76:83:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
template <typename T>
__device__ __forceinline__ T gelu_tanh(const T& x) {
  constexpr float kAlpha = 0.044715f;
  constexpr float kBeta = 0.7978845608028654f;
  float f32_val = detail::to_f32(x);
  const float cdf = 0.5f * (1.0f + tanhf((kBeta * (f32_val + kAlpha * f32_val * f32_val * f32_val))));
  return detail::from_f32<T>(f32_val * cdf);
}
```

**è¿‘ä¼¼å…¬å¼**ï¼š
```
cdf = 0.5 * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))
GELU(x) â‰ˆ x * cdf
```

**ä¼˜åŠ¿**ï¼š
- `tanh` æ¯” `erf` è®¡ç®—æ›´å¿«
- ç²¾åº¦è¶³å¤Ÿï¼ˆè¯¯å·® < 0.003ï¼‰

### 4. SiLU and Mulï¼ˆèåˆæ“ä½œï¼‰

```85:104:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
void silu_and_mul(at::Tensor& out, at::Tensor& input) {
  int d = input.size(-1) / 2;
  int64_t num_tokens = input.numel() / input.size(-1);
  dim3 grid(num_tokens);

  const cudaStream_t stream = at::cuda::getCurrentCUDAStream();
  const at::cuda::OptionalCUDAGuard device_guard(device_of(input));

  DISPATCH_PYTORCH_DTYPE_TO_CTYPE_FLOAT_FP16(input.scalar_type(), c_type, [&] {
    uint32_t vec_size = 16 / sizeof(c_type);
    dim3 block(std::min(d / vec_size, 1024U));
#if USE_ROCM
    sgl_hip::activation::act_and_mul_kernel<c_type, silu>
        <<<grid, block, 0, stream>>>(static_cast<c_type*>(out.data_ptr()), static_cast<c_type*>(input.data_ptr()), d);
#else
    flashinfer::activation::act_and_mul_kernel<c_type, silu>
        <<<grid, block, 0, stream>>>(static_cast<c_type*>(out.data_ptr()), static_cast<c_type*>(input.data_ptr()), d);
#endif
    return true;
  });
}
```

#### ä»£ç è§£æ

**é…ç½®å‚æ•°**ï¼š
```cpp
int d = input.size(-1) / 2;              // ä¸€åŠç»´åº¦
int64_t num_tokens = input.numel() / input.size(-1);  // token æ•°é‡
dim3 grid(num_tokens);                    // æ¯ä¸ª token ä¸€ä¸ª block
```

**å‘é‡åŒ–è®¡ç®—**ï¼š
```cpp
uint32_t vec_size = 16 / sizeof(c_type);  // å‘é‡å¤§å°
dim3 block(std::min(d / vec_size, 1024U));  // æ ¹æ®å‘é‡å¤§å°è°ƒæ•´ block
```

**å‘é‡åŒ–ç¤ºä¾‹**ï¼š
- `half` ç±»å‹ï¼š`sizeof(half) = 2` â†’ `vec_size = 16/2 = 8`
- `float` ç±»å‹ï¼š`sizeof(float) = 4` â†’ `vec_size = 16/4 = 4`
- ä¸€æ¬¡åŠ è½½/å­˜å‚¨ 8 ä¸ª `half` æˆ– 4 ä¸ª `float`

---

## ğŸ¯ å®Œæ•´ç¤ºä¾‹ï¼šSiLU å®ç°

### ç®€åŒ–ç‰ˆï¼ˆä¸ä¾èµ–å¤–éƒ¨åº“ï¼‰

```cpp
#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <stdio.h>
#include <math.h>

// SiLU å‡½æ•°ï¼ˆæ”¯æŒ half å’Œ floatï¼‰
template<typename T>
__device__ __forceinline__ float silu_impl(float x) {
    return x / (1.0f + expf(-x));
}

template<typename T>
__device__ __forceinline__ T silu(const T& x) {
    if constexpr (sizeof(T) == 2) {
        // half ç±»å‹ï¼šè½¬ float è®¡ç®—
        float f32_val = __half2float((__half)x);
        float result = silu_impl<T>(f32_val);
        return (T)__float2half(result);
    } else {
        // float ç±»å‹ï¼šç›´æ¥è®¡ç®—
        return (T)silu_impl<T>((float)x);
    }
}

// Kernelï¼šSiLU æ¿€æ´»
template<typename T>
__global__ void silu_kernel(const T* input, T* output, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;
    
    // Grid-Stride Loop
    for (int i = idx; i < N; i += stride) {
        output[i] = silu<T>(input[i]);
    }
}

// ä¸»æœºç«¯è°ƒç”¨
template<typename T>
void silu_cuda(const T* d_input, T* d_output, int N) {
    const int threads_per_block = 256;
    const int max_blocks = 1024;
    int blocks = (N + threads_per_block - 1) / threads_per_block;
    blocks = blocks < max_blocks ? blocks : max_blocks;
    
    silu_kernel<T><<<blocks, threads_per_block>>>(
        d_input, d_output, N);
    
    cudaDeviceSynchronize();
}

int main() {
    const int N = 10000;
    
    // ä¸»æœºç«¯æ•°æ®
    float* h_input = (float*)malloc(N * sizeof(float));
    float* h_output = (float*)malloc(N * sizeof(float));
    
    // åˆå§‹åŒ–è¾“å…¥
    for (int i = 0; i < N; i++) {
        h_input[i] = (float)(i - N/2) / (N/10.0f);  // èŒƒå›´ [-5, 5]
    }
    
    // è®¾å¤‡ç«¯æ•°æ®
    float* d_input;
    float* d_output;
    cudaMalloc(&d_input, N * sizeof(float));
    cudaMalloc(&d_output, N * sizeof(float));
    
    // å¤åˆ¶åˆ°è®¾å¤‡
    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);
    
    // æ‰§è¡Œ SiLU
    silu_cuda<float>(d_input, d_output, N);
    
    // å¤åˆ¶å›ä¸»æœº
    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);
    
    // éªŒè¯ç»“æœ
    printf("Input -> Output:\n");
    for (int i = 0; i < 10; i++) {
        float expected = h_input[i] / (1.0f + expf(-h_input[i]));
        printf("  %.2f -> %.4f (expected: %.4f)\n", 
               h_input[i], h_output[i], expected);
    }
    
    // æ¸…ç†
    free(h_input);
    free(h_output);
    cudaFree(d_input);
    cudaFree(d_output);
    
    return 0;
}
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. å‘é‡åŒ–åŠ è½½/å­˜å‚¨

```cpp
// ä¸€æ¬¡åŠ è½½ 4 ä¸ª float æˆ– 8 ä¸ª half
using vec_t = float4;  // æˆ– half8

__device__ void silu_vectorized(const vec_t* input, vec_t* output, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    for (int i = idx; i < N; i += blockDim.x * gridDim.x) {
        vec_t vec_input = input[i];
        // å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨ SiLU
        vec_t vec_output;
        // ... å¤„ç† ...
        output[i] = vec_output;
    }
}
```

**ä¼˜åŠ¿**ï¼š
- å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°
- æé«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
- é™ä½æŒ‡ä»¤å¼€é”€

### 2. ä½¿ç”¨å¿«é€Ÿæ•°å­¦å‡½æ•°

```cpp
// ä½¿ç”¨ __expfï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰
float fast_silu(float x) {
    return x / (1.0f + __expf(-x));
}
```

**æƒè¡¡**ï¼š
- é€Ÿåº¦æ›´å¿«ï¼ˆçº¦ 2xï¼‰
- ç²¾åº¦ç•¥ä½ï¼ˆé€šå¸¸è¶³å¤Ÿï¼‰

### 3. æ•°å€¼ç¨³å®šæ€§ä¼˜åŒ–

```cpp
__device__ float silu_stable(float x) {
    // å¯¹äºå¤§è´Ÿæ•°ï¼Œé¿å… exp æº¢å‡º
    if (x < -20.0f) {
        return x;  // è¿‘ä¼¼ï¼šsilu(x) â‰ˆ x when x << 0
    }
    // å¯¹äºå¤§æ­£æ•°ï¼Œé¿å…è®¡ç®— exp(-x)
    if (x > 20.0f) {
        return x;  // è¿‘ä¼¼ï¼šsilu(x) â‰ˆ x when x >> 0
    }
    // æ­£å¸¸è®¡ç®—
    return x / (1.0f + expf(-x));
}
```

---

## ğŸ” ä¸å…¶ä»–æ¿€æ´»å‡½æ•°å¯¹æ¯”

### å¸¸è§æ¿€æ´»å‡½æ•°

| æ¿€æ´»å‡½æ•° | å…¬å¼ | ç‰¹ç‚¹ |
|---------|------|------|
| **ReLU** | `max(0, x)` | ç®€å•ã€å¿«é€Ÿï¼Œä½†ä¸å¯å¾®åœ¨ 0 å¤„ |
| **SiLU** | `x / (1 + exp(-x))` | å¹³æ»‘ã€å¯å¾®ï¼Œæ€§èƒ½å¥½ |
| **GELU** | `x * 0.5 * (1 + erf(x/âˆš2))` | æ›´å¹³æ»‘ï¼Œä½†è®¡ç®—æ…¢ |
| **Sigmoid** | `1 / (1 + exp(-x))` | è¾“å‡º [0, 1]ï¼Œæ˜“é¥±å’Œ |

### åœ¨ LLM ä¸­çš„åº”ç”¨

- **Llama ç³»åˆ—**ï¼šä½¿ç”¨ SiLUï¼ˆSwiGLUï¼‰
- **BERT**ï¼šä½¿ç”¨ GELU
- **GPT-2**ï¼šä½¿ç”¨ GELU
- **GPT-3/4**ï¼šä½¿ç”¨ GELU

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒæ¦‚å¿µ

1. **é€å…ƒç´ æ“ä½œ**ï¼šæ¯ä¸ªå…ƒç´ ç‹¬ç«‹è®¡ç®—
2. **ç±»å‹è½¬æ¢**ï¼š`half` â†’ `float` â†’ è®¡ç®— â†’ `half`
3. **æ•°å€¼ç¨³å®šæ€§**ï¼šå¤„ç†æç«¯å€¼ï¼ˆå¤§æ­£æ•°/å¤§è´Ÿæ•°ï¼‰
4. **å‘é‡åŒ–**ï¼šä¸€æ¬¡å¤„ç†å¤šä¸ªå…ƒç´ 

### å…³é”®ç‚¹

- âœ… **ç®€å•ä½†é‡è¦**ï¼šæ¿€æ´»å‡½æ•°æ˜¯ç¥ç»ç½‘ç»œçš„åŸºç¡€
- âœ… **è®¡ç®—å¯†é›†**ï¼šLLM ä¸­éœ€è¦å¤„ç†å¤§é‡ token
- âœ… **å¹¶è¡Œå‹å¥½**ï¼šå®Œå…¨ç‹¬ç«‹ï¼Œæ— ä¾èµ–
- âœ… **æ•°å€¼ç²¾åº¦**ï¼šéœ€è¦æ³¨æ„ç±»å‹è½¬æ¢

### å­¦ä¹ ä»·å€¼

æ¿€æ´»å‡½æ•°æ˜¯å­¦ä¹  CUDA çš„**ç¬¬äºŒä¸ªé‡è¦ç®—å­**ï¼Œå› ä¸ºå®ƒï¼š
- å±•ç¤ºäº†è®¾å¤‡ç«¯å‡½æ•°çš„ä½¿ç”¨
- è¯´æ˜äº†ç±»å‹è½¬æ¢æŠ€å·§
- æ¼”ç¤ºäº†ç®€å•çš„æ•°å­¦è¿ç®—
- ä¸ºç†è§£æ›´å¤æ‚çš„ç®—å­æ‰“ä¸‹åŸºç¡€

---

## ğŸ”— ç›¸å…³èµ„æº

- **ä¸‹ä¸€ä¸ªç®—å­**ï¼š[03_Lightning_Attention_Decode.md](./03_Lightning_Attention_Decode.md)
- **SwiGLU è®ºæ–‡**ï¼šGLU Variants Improve Transformer
- **GELU è®ºæ–‡**ï¼šGaussian Error Linear Units (GELUs)

