# SGLang CUDA 算子讲解目录

## 📚 文档索引

本文档目录包含 SGLang 中主要 CUDA 算子的详细讲解，每个算子文档都包含：

1. **公式与算法**：数学公式和算法原理
2. **算法原理**：详细的算法说明和流程
3. **代码实现**：完整的代码分析和逐行解析

---

## 📖 算子列表

### 基础算子（⭐⭐）

#### 1. [Copy 算子](./01_Copy算子.md)
- **功能**：将数据从 CPU 复制到 GPU
- **难度**：⭐⭐
- **学习点**：CUDA kernel 基础、线程索引、边界检查
- **源码**：`elementwise/copy.cu`

#### 2. [Activation 算子](./02_Activation算子.md)（SiLU / GELU）
- **功能**：激活函数计算（SiLU、GELU 等）
- **难度**：⭐⭐
- **学习点**：设备端函数、类型转换、向量化调用
- **源码**：`elementwise/activation.cu`

---

### 中级算子（⭐⭐⭐）

#### 3. [Lightning Attention Decode](./03_Lightning_Attention_Decode.md)
- **功能**：解码阶段的注意力计算
- **难度**：⭐⭐⭐⭐
- **学习点**：
  - 共享内存使用
  - 线程协作模式
  - KV Cache 更新
  - 矩阵向量乘法优化
- **源码**：`attention/lightning_attention_decode_kernel.cu`

#### 4. [RoPE 算子](./04_RoPE算子.md)
- **功能**：旋转位置编码
- **难度**：⭐⭐⭐
- **学习点**：
  - 复数旋转
  - 预计算缓存
  - 向量化实现
  - 内存访问优化
- **源码**：`elementwise/rope.cu`

#### 5. [Fused Add RMSNorm](./06_Fused_Add_RMSNorm.md)
- **功能**：融合的残差连接和归一化
- **难度**：⭐⭐⭐
- **学习点**：
  - 融合操作设计
  - 并行归约
  - 内存访问优化
- **源码**：`elementwise/fused_add_rms_norm_kernel.cu`

---

### 高级算子（⭐⭐⭐⭐⭐）

#### 6. [TopK 算子](./05_TopK算子.md)
- **功能**：从数组中找出最大的 K 个元素
- **难度**：⭐⭐⭐⭐⭐
- **学习点**：
  - 基数排序算法
  - 并行前缀和
  - 共享内存优化
  - 原子操作
- **源码**：`elementwise/topk.cu`

---

## 🎯 学习路径建议

### 路径 1：从简单到复杂（推荐）

```
1. Copy 算子          (⭐⭐)  → 理解 CUDA kernel 基础
2. Activation 算子    (⭐⭐)  → 学习设备端函数和类型转换
3. Fused Add RMSNorm  (⭐⭐⭐) → 学习融合操作和归约
4. RoPE 算子          (⭐⭐⭐) → 学习复杂数学运算
5. Lightning Attention(⭐⭐⭐⭐) → 学习共享内存和线程协作
6. TopK 算子          (⭐⭐⭐⭐⭐) → 学习复杂算法
```

### 路径 2：按功能分组

**逐元素操作**：
- Copy → Activation → Fused Add RMSNorm

**位置编码**：
- RoPE

**注意力机制**：
- Lightning Attention Decode

**采样和排序**：
- TopK

---

## 📊 难度对比表

| 算子 | 难度 | 代码复杂度 | 算法复杂度 | 学习时间 |
|------|------|-----------|-----------|---------|
| Copy | ⭐⭐ | 低 | O(N) | 30 分钟 |
| Activation | ⭐⭐ | 低 | O(N) | 1 小时 |
| Fused Add RMSNorm | ⭐⭐⭐ | 中 | O(N) | 2 小时 |
| RoPE | ⭐⭐⭐ | 中 | O(N) | 2-3 小时 |
| Lightning Attention | ⭐⭐⭐⭐ | 高 | O(N²) | 3-4 小时 |
| TopK | ⭐⭐⭐⭐⭐ | 很高 | O(N log N) | 4-5 小时 |

---

## 🔍 每个文档的结构

每个算子文档包含以下部分：

### 1. 算子概述
- 功能说明
- 用途和应用场景
- 特点

### 2. 公式与算法
- **数学公式**：准确的数学定义
- **算法步骤**：详细的算法流程
- **复杂度分析**：时间和空间复杂度

### 3. 算法原理
- **基本思路**：算法的核心思想
- **设计动机**：为什么这样设计
- **优化考虑**：性能优化思路

### 4. 代码实现
- **源码位置**：文件路径
- **完整代码**：使用代码引用格式
- **逐行解析**：详细解释每一行
- **关键设计**：重要的设计选择

### 5. 设计要点
- **优化技巧**：性能优化方法
- **陷阱和注意事项**：常见错误
- **与其他实现对比**：与其他方法的比较

### 6. 总结
- **核心概念**：需要掌握的关键点
- **学习价值**：这个算子能学到什么
- **下一步**：相关资源链接

---

## 💡 学习建议

### 1. 先理解再编码

不要直接看代码，先：
1. 理解数学公式
2. 理解算法原理
3. 画出算法流程图
4. 再去看代码

### 2. 动手实践

对于每个算子：
1. 阅读文档
2. 理解代码
3. 写简化版本验证理解
4. 运行并验证结果

### 3. 对比学习

对比：
- SGLang vs PyTorch 的实现
- 简单版本 vs 优化版本
- 不同优化技巧的效果

### 4. 工具辅助

使用调试和分析工具：
- `cuda-gdb`：调试 CUDA 代码
- `nsight-compute`：分析性能
- `nsight-systems`：查看时间线

---

## 📚 额外资源

### 参考资料

- **SGLang 官方文档**：https://github.com/sgl-project/sglang
- **FlashInfer**：SGLang 使用的底层库
- **CUDA 编程指南**：NVIDIA CUDA C++ Programming Guide
- **CUDA 最佳实践**：CUDA Best Practices Guide

### 相关文档

- **SGLang_CUDA源码分析.md**：整体架构分析
- **CUDA算子实现详解.md**：PyTorch 算子对比（理解封装 vs 直接实现）

---

## 🎓 学习成果

完成所有算子学习后，你将能够：

1. ✅ **理解 CUDA 编程模型**：thread、block、grid 的使用
2. ✅ **掌握共享内存优化**：何时使用、如何使用
3. ✅ **理解并行算法**：归约、排序、矩阵乘法
4. ✅ **掌握性能优化**：内存访问、向量化、融合操作
5. ✅ **编写高效 kernel**：从算法到实现

---

## 📝 贡献指南

如果你发现文档有错误或可以改进的地方，欢迎：
1. 修正错误
2. 补充示例
3. 添加更多可视化
4. 提供简化版本代码

---

**开始学习**：建议从 [01_Copy算子.md](./01_Copy算子.md) 开始！

