# SGLang CUDA æºç åˆ†æ

## ğŸ“– ä¸ºä»€ä¹ˆ SGLang æ›´é€‚åˆå­¦ä¹  CUDAï¼Ÿ

ç›¸æ¯” PyTorchï¼ŒSGLang çš„ CUDA ä»£ç æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

### âœ… **æ›´ç›´æ¥**ï¼šä»£ç æ›´æ¥è¿‘ CUDA å†…æ ¸çš„æœ¬è´¨
- **PyTorch**ï¼šå¤šå±‚å°è£…ï¼ˆTensorIteratorã€Dispatchã€Functor ç­‰ï¼‰ï¼ŒæŠ½è±¡å±‚æ¬¡é«˜
- **SGLang**ï¼šç›´æ¥å†™ CUDA kernelï¼Œé€»è¾‘æ¸…æ™°ï¼Œå®¹æ˜“ç†è§£

### âœ… **æ›´å®ç”¨**ï¼šä¸“æ³¨äº LLM æ¨ç†çš„å®é™…éœ€æ±‚
- Attention è§£ç 
- RoPE ä½ç½®ç¼–ç 
- æ¿€æ´»å‡½æ•°ï¼ˆSiLUã€GELUï¼‰
- TopK é‡‡æ ·
- è¿™äº›éƒ½æ˜¯ LLM æ¨ç†ä¸­çš„æ ¸å¿ƒæ“ä½œ

### âœ… **æ›´å®¹æ˜“ç†è§£**ï¼šä»£ç ç»“æ„ç®€å•
- ä¸€ä¸ªæ–‡ä»¶ä¸€ä¸ªåŠŸèƒ½
- Kernel å®ç°ç›´è§‚
- å…±äº«å†…å­˜ä½¿ç”¨æ¸…æ™°

---

## ğŸ“ SGLang CUDA ä»£ç ç»“æ„

### æ ¸å¿ƒç›®å½•

```
sgl-kernel/csrc/
â”œâ”€â”€ attention/          # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ lightning_attention_decode_kernel.cu  # è§£ç é˜¶æ®µæ³¨æ„åŠ›
â”‚   â”œâ”€â”€ cutlass_mla_kernel.cu                # CUTLASS ä¼˜åŒ–çš„ MLA
â”‚   â””â”€â”€ merge_attn_states.cu                 # åˆå¹¶æ³¨æ„åŠ›çŠ¶æ€
â”œâ”€â”€ elementwise/        # é€å…ƒç´ æ“ä½œ
â”‚   â”œâ”€â”€ activation.cu   # æ¿€æ´»å‡½æ•°ï¼ˆSiLUã€GELUï¼‰
â”‚   â”œâ”€â”€ rope.cu         # RoPE ä½ç½®ç¼–ç 
â”‚   â”œâ”€â”€ copy.cu         # å†…å­˜æ‹·è´
â”‚   â””â”€â”€ topk.cu         # TopK é‡‡æ ·
â”œâ”€â”€ gemm/              # çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰
â”‚   â””â”€â”€ [å„ç§é‡åŒ– GEMM]
â”œâ”€â”€ moe/               # æ··åˆä¸“å®¶ï¼ˆMoEï¼‰
â””â”€â”€ quantization/      # é‡åŒ–ç›¸å…³
```

---

## 1ï¸âƒ£ æœ€ç®€å•çš„ä¾‹å­ï¼šæ¿€æ´»å‡½æ•°ï¼ˆSiLUï¼‰

### 1.1 ç®—å­è¯´æ˜

**SiLU (Swish)**ï¼š`silu(x) = x / (1 + exp(-x))`

è¿™æ˜¯ LLM ä¸­æœ€å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°ä¹‹ä¸€ï¼ˆå¦‚ Llama ä½¿ç”¨ SiLUï¼‰ã€‚

### 1.2 æºç å®ç°

```56:60:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
template <typename T>
__device__ __forceinline__ T silu(const T& x) {
  float f32_val = detail::to_f32(x);
  return detail::from_f32<T>(f32_val / (1.0f + expf(-f32_val)));
}
```

**ä»£ç è§£æ**ï¼š
- **ç›´æ¥æ˜äº†**ï¼šå°±æ˜¯æ•°å­¦å…¬å¼çš„ä»£ç å®ç°
- **ç±»å‹è½¬æ¢**ï¼šå…ˆè½¬ float32 è®¡ç®—ï¼Œå†è½¬å›åŸç±»å‹ï¼ˆé¿å…ç²¾åº¦é—®é¢˜ï¼‰
- `__device__ __forceinline__`ï¼šè®¾å¤‡ç«¯å‡½æ•°ï¼Œå¼ºåˆ¶å†…è”

### 1.3 ä¸»æœºç«¯è°ƒç”¨

```85:104:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/activation.cu
void silu_and_mul(at::Tensor& out, at::Tensor& input) {
  int d = input.size(-1) / 2;
  int64_t num_tokens = input.numel() / input.size(-1);
  dim3 grid(num_tokens);

  const cudaStream_t stream = at::cuda::getCurrentCUDAStream();
  const at::cuda::OptionalCUDAGuard device_guard(device_of(input));

  DISPATCH_PYTORCH_DTYPE_TO_CTYPE_FLOAT_FP16(input.scalar_type(), c_type, [&] {
    uint32_t vec_size = 16 / sizeof(c_type);
    dim3 block(std::min(d / vec_size, 1024U));
#if USE_ROCM
    sgl_hip::activation::act_and_mul_kernel<c_type, silu>
        <<<grid, block, 0, stream>>>(static_cast<c_type*>(out.data_ptr()), static_cast<c_type*>(input.data_ptr()), d);
#else
    flashinfer::activation::act_and_mul_kernel<c_type, silu>
        <<<grid, block, 0, stream>>>(static_cast<c_type*>(out.data_ptr()), static_cast<c_type*>(input.data_ptr()), d);
#endif
    return true;
  });
}
```

**å…³é”®ç‚¹**ï¼š
- **ç›´æ¥è°ƒç”¨**ï¼š`<<<grid, block>>>` å¯åŠ¨ kernel
- **å‘é‡åŒ–**ï¼š`vec_size = 16 / sizeof(c_type)` è‡ªåŠ¨è®¡ç®—å‘é‡å¤§å°
- **Grid é…ç½®**ï¼šæ¯ä¸ª token ä¸€ä¸ª blockï¼ˆ`grid(num_tokens)`ï¼‰
- **Block é…ç½®**ï¼šæ ¹æ®ç»´åº¦å¤§å°åŠ¨æ€è°ƒæ•´

---

## 2ï¸âƒ£ æ ¸å¿ƒä¾‹å­ï¼šLightning Attention Decodeï¼ˆè§£ç é˜¶æ®µæ³¨æ„åŠ›ï¼‰

### 2.1 ç®—å­è¯´æ˜

è¿™æ˜¯ LLM **è§£ç é˜¶æ®µ**çš„æ³¨æ„åŠ›è®¡ç®—ï¼Œæ¯”é¢„å¡«å……é˜¶æ®µç®€å•å¾—å¤šï¼š
- è¾“å…¥ï¼šå½“å‰ step çš„ q, k, vï¼ˆå½¢çŠ¶ `[batch, heads, 1, dim]`ï¼‰
- è¿‡å»ï¼špast_kvï¼ˆå½¢çŠ¶ `[batch, heads, qk_dim, v_dim]`ï¼‰
- è¾“å‡ºï¼šæ³¨æ„åŠ›ç»“æœå’Œæ›´æ–°çš„ kv cache

**å…³é”®ç‰¹ç‚¹**ï¼š
- **å¢é‡è®¡ç®—**ï¼šåªè®¡ç®—å½“å‰ token çš„æ³¨æ„åŠ›
- **ä½¿ç”¨å…±äº«å†…å­˜**ï¼šq, k, v è½½å…¥å…±äº«å†…å­˜å¤ç”¨
- **KV Cache æ›´æ–°**ï¼šèåˆæ›´æ–°æ“ä½œ

### 2.2 æ ¸å¿ƒ Kernel ä»£ç 

```25:113:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/attention/lightning_attention_decode_kernel.cu
template <typename T>
__global__ void lightning_attention_decode_kernel(
    const T* __restrict__ q,            // [b, h, 1, d]
    const T* __restrict__ k,            // [b, h, 1, d]
    const T* __restrict__ v,            // [b, h, 1, e]
    const float* __restrict__ past_kv,  // [b, h, d, e]
    const float* __restrict__ slope,    // [h, 1, 1]
    T* __restrict__ output,             // [b, h, 1, e]
    float* __restrict__ new_kv,         // [b, h, d, e]
    const int batch_size,
    const int num_heads,
    const int qk_dim,
    const int v_dim) {
  extern __shared__ char smem[];
  T* __restrict__ q_shared = reinterpret_cast<T*>(smem);
  T* __restrict__ k_shared = reinterpret_cast<T*>(smem + qk_dim * sizeof(T));
  T* __restrict__ v_shared = reinterpret_cast<T*>(smem + 2 * qk_dim * sizeof(T));
  float* __restrict__ new_kv_shared = reinterpret_cast<float*>(smem + (2 * qk_dim + v_dim) * sizeof(T));
  T* __restrict__ output_shared =
      reinterpret_cast<T*>(smem + (2 * qk_dim + v_dim) * sizeof(T) + qk_dim * (v_dim + 1) * sizeof(float));

  const int32_t tid = threadIdx.x;
  const int32_t current_head = blockIdx.x;
  const int32_t b = current_head / num_heads;
  const int32_t h = current_head % num_heads;

  if (b >= batch_size) return;

  const int32_t qk_offset = b * num_heads * qk_dim + h * qk_dim;
  const int32_t v_offset = b * num_heads * v_dim + h * v_dim;
  const int32_t kv_offset = b * num_heads * qk_dim * v_dim + h * qk_dim * v_dim;

  // Load q, k, v into shared memory
  for (int d = tid; d < qk_dim; d += blockDim.x) {
    q_shared[d] = q[qk_offset + d];
    k_shared[d] = k[qk_offset + d];
  }
  for (int e = tid; e < v_dim; e += blockDim.x) {
    v_shared[e] = v[v_offset + e];
  }

  __syncthreads();

  const float ratio = expf(-1.0f * slope[h]);

  // Compute new_kv
  for (int d = tid; d < qk_dim; d += blockDim.x) {
    const T k_val = k_shared[d];
    for (int e = 0; e < v_dim; ++e) {
      const int past_kv_idx = kv_offset + d * v_dim + e;
      const T v_val = v_shared[e];
      const float new_val = ratio * past_kv[past_kv_idx] + k_val * v_val;
      const int shared_idx = d * (v_dim + 1) + e;
      new_kv_shared[shared_idx] = new_val;
    }
  }

  __syncthreads();

  // Store new_kv to global memory
  for (int idx = tid; idx < qk_dim * v_dim; idx += blockDim.x) {
    const int d = idx / v_dim;
    const int e = idx % v_dim;
    const int shared_idx = d * (v_dim + 1) + e;
    const int global_idx = kv_offset + idx;
    new_kv[global_idx] = new_kv_shared[shared_idx];
  }

  __syncthreads();

  // Compute output
  for (int e = tid; e < v_dim; e += blockDim.x) {
    float sum = 0.0f;
    for (int d = 0; d < qk_dim; ++d) {
      const int shared_idx = d * (v_dim + 1) + e;
      sum += q_shared[d] * new_kv_shared[shared_idx];
    }
    output_shared[e] = static_cast<T>(sum);
  }

  __syncthreads();

  // Store output to global memory
  if (tid == 0) {
    for (int e = 0; e < v_dim; ++e) {
      output[v_offset + e] = output_shared[e];
    }
  }
}
```

### 2.3 ä»£ç æµç¨‹è¯¦è§£

#### ç¬¬ä¸€æ­¥ï¼šåˆ†é…å…±äº«å†…å­˜

```cpp
extern __shared__ char smem[];
T* q_shared = reinterpret_cast<T*>(smem);
T* k_shared = reinterpret_cast<T*>(smem + qk_dim * sizeof(T));
T* v_shared = reinterpret_cast<T*>(smem + 2 * qk_dim * sizeof(T));
float* new_kv_shared = reinterpret_cast<float*>(smem + (2 * qk_dim + v_dim) * sizeof(T));
```

**å…³é”®ç‚¹**ï¼š
- **åŠ¨æ€å…±äº«å†…å­˜**ï¼š`extern __shared__ char smem[]`
- **æ‰‹åŠ¨å¸ƒå±€**ï¼šåœ¨å…±äº«å†…å­˜ä¸­æ‰‹åŠ¨åˆ†é…å„ä¸ªæ•°ç»„çš„ä½ç½®
- **ç±»å‹è½¬æ¢**ï¼šä½¿ç”¨ `reinterpret_cast` åœ¨ä¸åŒç±»å‹é—´åˆ‡æ¢

#### ç¬¬äºŒæ­¥ï¼šè®¡ç®—çº¿ç¨‹ç´¢å¼•

```cpp
const int32_t tid = threadIdx.x;              // çº¿ç¨‹åœ¨ block å†…çš„ç´¢å¼•
const int32_t current_head = blockIdx.x;      // å½“å‰ blockï¼ˆæ¯ä¸ª head ä¸€ä¸ª blockï¼‰
const int32_t b = current_head / num_heads;   // batch ç´¢å¼•
const int32_t h = current_head % num_heads;   // head ç´¢å¼•
```

**è®¾è®¡æ¨¡å¼**ï¼š
- **æ¯ä¸ª head ä¸€ä¸ª block**ï¼šç®€åŒ–åŒæ­¥ï¼Œæ¯ä¸ª head ç‹¬ç«‹å¤„ç†
- **Grid é…ç½®**ï¼š`grid(batch_size * num_heads)`

#### ç¬¬ä¸‰æ­¥ï¼šåŠ è½½æ•°æ®åˆ°å…±äº«å†…å­˜

```cpp
for (int d = tid; d < qk_dim; d += blockDim.x) {
  q_shared[d] = q[qk_offset + d];
  k_shared[d] = k[qk_offset + d];
}
```

**å…³é”®ç‚¹**ï¼š
- **åä½œåŠ è½½**ï¼šå¤šä¸ªçº¿ç¨‹åä½œåŠ è½½ä¸€ä¸ªæ•°ç»„
- **åˆå¹¶è®¿é—®**ï¼šå¦‚æœè¿ç»­è®¿é—®ï¼Œä¼šäº§ç”Ÿåˆå¹¶å†…å­˜è®¿é—®
- **åŒæ­¥**ï¼šåŠ è½½å®Œæˆå `__syncthreads()`

#### ç¬¬å››æ­¥ï¼šæ›´æ–° KV Cache

```cpp
const float ratio = expf(-1.0f * slope[h]);  // è¡°å‡å› å­

for (int d = tid; d < qk_dim; d += blockDim.x) {
  const T k_val = k_shared[d];
  for (int e = 0; e < v_dim; ++e) {
    const float new_val = ratio * past_kv[past_kv_idx] + k_val * v_val;
    new_kv_shared[shared_idx] = new_val;
  }
}
```

**è®¡ç®—å…¬å¼**ï¼š
```
new_kv = ratio * old_kv + k * v
```
- **ratio**ï¼šè¡°å‡å› å­ï¼ˆåŸºäº slopeï¼‰ï¼Œå®ç°æ»‘åŠ¨çª—å£æ³¨æ„åŠ›
- **å¢é‡æ›´æ–°**ï¼šç›´æ¥æ›´æ–° KV cacheï¼Œä¸éœ€è¦é‡æ–°è®¡ç®—

#### ç¬¬äº”æ­¥ï¼šè®¡ç®—æ³¨æ„åŠ›è¾“å‡º

```cpp
for (int e = tid; e < v_dim; e += blockDim.x) {
  float sum = 0.0f;
  for (int d = 0; d < qk_dim; ++d) {
    sum += q_shared[d] * new_kv_shared[shared_idx];  // q * kv
  }
  output_shared[e] = static_cast<T>(sum);
}
```

**å…³é”®ç‚¹**ï¼š
- **çŸ©é˜µå‘é‡ä¹˜æ³•**ï¼š`q * kv` å¾—åˆ°è¾“å‡º
- **å¯„å­˜å™¨ç´¯åŠ **ï¼šä½¿ç”¨ `float sum` åœ¨å¯„å­˜å™¨ä¸­ç´¯åŠ 
- **å…±äº«å†…å­˜å¤ç”¨**ï¼š`q_shared` å’Œ `new_kv_shared` éƒ½åœ¨å…±äº«å†…å­˜ä¸­

### 2.4 ä¸»æœºç«¯è°ƒç”¨

```115:154:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/attention/lightning_attention_decode_kernel.cu
void lightning_attention_decode(
    const torch::Tensor& q,
    const torch::Tensor& k,
    const torch::Tensor& v,
    const torch::Tensor& past_kv,
    const torch::Tensor& slope,
    torch::Tensor output,
    torch::Tensor new_kv) {
  TORCH_CHECK(q.is_contiguous(), "q must be contiguous");
  TORCH_CHECK(k.is_contiguous(), "k must be contiguous");
  TORCH_CHECK(v.is_contiguous(), "v must be contiguous");
  TORCH_CHECK(past_kv.is_contiguous(), "past_kv must be contiguous");

  auto batch_size = q.size(0);
  auto num_heads = q.size(1);
  auto qk_dim = q.size(3);
  auto v_dim = v.size(3);

  dim3 block(THREADS_PER_BLOCK);  // 128 ä¸ªçº¿ç¨‹
  dim3 grid(batch_size * num_heads);  // æ¯ä¸ª head ä¸€ä¸ª block

  const cudaStream_t stream = at::cuda::getCurrentCUDAStream();

  AT_DISPATCH_FLOATING_TYPES_AND2(
      at::ScalarType::Half, at::ScalarType::BFloat16, q.scalar_type(), "lightning_attention_decode_kernel", ([&] {
        size_t smem_size = (2 * qk_dim + 2 * v_dim) * sizeof(scalar_t) + qk_dim * (v_dim + 1) * sizeof(float);
        lightning_attention_decode_kernel<scalar_t><<<grid, block, smem_size, stream>>>(
            q.data_ptr<scalar_t>(),
            k.data_ptr<scalar_t>(),
            v.data_ptr<scalar_t>(),
            past_kv.data_ptr<float>(),
            slope.data_ptr<float>(),
            output.data_ptr<scalar_t>(),
            new_kv.data_ptr<float>(),
            batch_size,
            num_heads,
            qk_dim,
            v_dim);
      }));
}
```

**å…³é”®é…ç½®**ï¼š
- **Block å¤§å°**ï¼š`THREADS_PER_BLOCK = 128`
- **Grid å¤§å°**ï¼š`batch_size * num_heads`ï¼ˆæ¯ä¸ª head ä¸€ä¸ª blockï¼‰
- **å…±äº«å†…å­˜å¤§å°**ï¼šåŠ¨æ€è®¡ç®—ï¼ŒåŒ…å«æ‰€æœ‰ä¸­é—´æ•°ç»„

---

## 3ï¸âƒ£ å®ç”¨æŠ€å·§ï¼šTopK é‡‡æ ·

TopK æ˜¯ LLM æ¨ç†ä¸­çš„å…³é”®æ“ä½œï¼ŒSGLang çš„å®ç°éå¸¸é«˜æ•ˆã€‚

### 3.1 æ ¸å¿ƒä»£ç ç‰‡æ®µ

```76:142:SGLangå­¦ä¹ /sglang/sgl-kernel/csrc/elementwise/topk.cu
__device__ void fast_topk_cuda_tl(const float* __restrict__ input, int* __restrict__ index, int row_start, int length) {
  // An optimized topk kernel copied from tilelang kernel
  // We assume length > TopK here, or it will crash
  int topk = TopK;
  constexpr auto BLOCK_SIZE = 1024;
  constexpr auto RADIX = 256;
  constexpr auto SMEM_INPUT_SIZE = kSmem / (2 * sizeof(int));

  alignas(128) __shared__ int s_histogram_buf[2][RADIX + 128];
  alignas(128) __shared__ int s_counter;
  alignas(128) __shared__ int s_threshold_bin_id;
  alignas(128) __shared__ int s_num_input[2];

  auto& s_histogram = s_histogram_buf[0];
  // allocate for two rounds
  extern __shared__ int s_input_idx[][SMEM_INPUT_SIZE];

  const int tx = threadIdx.x;

  // stage 1: 8bit coarse histogram
  if (tx < RADIX + 1) s_histogram[tx] = 0;
  __syncthreads();

  for (int idx = tx; idx < length; idx += BLOCK_SIZE) {
    const auto bin = convert_to_uint8(input[idx + row_start]);
    ::atomicAdd(&s_histogram[bin], 1);
  }
  __syncthreads();

  const auto run_cumsum = [&] {
#pragma unroll 8
    for (int i = 0; i < 8; ++i) {
      static_assert(1 << 8 == RADIX);
      if (C10_LIKELY(tx < RADIX)) {
        const auto j = 1 << i;
        const auto k = i & 1;
        auto value = s_histogram_buf[k][tx];
        if (tx < RADIX - j) {
          value += s_histogram_buf[k][tx + j];
        }
        s_histogram_buf[k ^ 1][tx] = value;
      }
      __syncthreads();
    }
  };

  run_cumsum();
  if (tx < RADIX && s_histogram[tx] > topk && s_histogram[tx + 1] <= topk) {
    s_threshold_bin_id = tx;
    s_num_input[0] = 0;
    s_counter = 0;
  }
  __syncthreads();
```

**å…³é”®ç®—æ³•**ï¼š**åŸºæ•°æ’åºï¼ˆRadix Sortï¼‰** çš„æ€æƒ³
1. **ç›´æ–¹å›¾**ï¼šå°† float è½¬æ¢ä¸º uint8ï¼Œæ„å»ºç›´æ–¹å›¾
2. **ç´¯ç§¯å’Œ**ï¼šè®¡ç®—æ¯ä¸ª bin çš„ç´¯ç§¯æ•°é‡
3. **é˜ˆå€¼æŸ¥æ‰¾**ï¼šæ‰¾åˆ°åŒ…å« TopK çš„ bin
4. **ç²¾ç»†æ’åº**ï¼šåªåœ¨é˜ˆå€¼ bin å†…åšå®Œæ•´æ’åº

---

## ğŸ“Š SGLang vs PyTorchï¼šä»£ç å¯¹æ¯”

### ç›¸åŒåŠŸèƒ½çš„å®ç°å¯¹æ¯”

#### ä¾‹å­ 1ï¼šæ¿€æ´»å‡½æ•°

**PyTorch æ–¹å¼**ï¼š
```cpp
// å¤šå±‚å°è£…
FillFunctor -> gpu_kernel -> TensorIterator -> CUDALoops -> å®é™… kernel
```

**SGLang æ–¹å¼**ï¼š
```cpp
// ç›´æ¥å®šä¹‰ kernel å‡½æ•°
__device__ __forceinline__ T silu(const T& x) {
  float f32_val = detail::to_f32(x);
  return detail::from_f32<T>(f32_val / (1.0f + expf(-f32_val)));
}

// ç›´æ¥å¯åŠ¨
silu_kernel<<<grid, block>>>(...);
```

**ä¼˜åŠ¿**ï¼š
- âœ… **ç›´è§‚**ï¼šä¸€çœ‹å°±æ‡‚
- âœ… **ç®€å•**ï¼šæ²¡æœ‰æŠ½è±¡å±‚
- âœ… **å¯æ§**ï¼šå®Œå…¨æ§åˆ¶ kernel çš„è¡Œä¸º

### ä»£ç å¤æ‚åº¦å¯¹æ¯”

| æ–¹é¢ | PyTorch | SGLang |
|------|---------|--------|
| **æŠ½è±¡å±‚æ¬¡** | 5+ å±‚ | 1-2 å±‚ |
| **ä»£ç è¡Œæ•°** | ~200 è¡Œï¼ˆåŒ…å«æ‰€æœ‰å°è£…ï¼‰ | ~50 è¡Œ |
| **ç†è§£éš¾åº¦** | â­â­â­â­â­ | â­â­ |
| **æ€§èƒ½ä¼˜åŒ–** | è‡ªåŠ¨åŒ–ï¼Œä½†éš¾ä»¥æ§åˆ¶ | æ‰‹åŠ¨ä¼˜åŒ–ï¼Œå®Œå…¨å¯æ§ |
| **å­¦ä¹ ä»·å€¼** | ç†è§£ç³»ç»Ÿè®¾è®¡ | ç†è§£ CUDA æœ¬è´¨ |

---

## ğŸ¯ é€‚åˆå­¦ä¹ çš„ SGLang Kernel

### 1. **æ¿€æ´»å‡½æ•°**ï¼ˆ`elementwise/activation.cu`ï¼‰
- **éš¾åº¦**ï¼šâ­â­
- **å­¦ä¹ ç‚¹**ï¼š
  - ç®€å•çš„è®¾å¤‡ç«¯å‡½æ•°
  - ç±»å‹è½¬æ¢æŠ€å·§
  - å‘é‡åŒ–è°ƒç”¨

### 2. **Lightning Attention Decode**ï¼ˆ`attention/lightning_attention_decode_kernel.cu`ï¼‰
- **éš¾åº¦**ï¼šâ­â­â­â­
- **å­¦ä¹ ç‚¹**ï¼š
  - å…±äº«å†…å­˜ä½¿ç”¨
  - çº¿ç¨‹åä½œæ¨¡å¼
  - KV Cache æ›´æ–°
  - çŸ©é˜µå‘é‡ä¹˜æ³•ä¼˜åŒ–

### 3. **TopK é‡‡æ ·**ï¼ˆ`elementwise/topk.cu`ï¼‰
- **éš¾åº¦**ï¼šâ­â­â­â­â­
- **å­¦ä¹ ç‚¹**ï¼š
  - åŸºæ•°æ’åº
  - å…±äº«å†…å­˜ä¼˜åŒ–
  - åŸå­æ“ä½œ
  - å¤æ‚ç®—æ³•åœ¨ GPU ä¸Šçš„å®ç°

### 4. **Copy**ï¼ˆ`elementwise/copy.cu`ï¼‰
- **éš¾åº¦**ï¼šâ­
- **å­¦ä¹ ç‚¹**ï¼š
  - æœ€ç®€å•çš„ kernel
  - æ¨¡æ¿å‚æ•°ä½¿ç”¨
  - Grid-Stride Loop

### 5. **RoPE**ï¼ˆ`elementwise/rope.cu`ï¼‰
- **éš¾åº¦**ï¼šâ­â­â­
- **å­¦ä¹ ç‚¹**ï¼š
  - æ—‹è½¬ä½ç½®ç¼–ç 
  - å¤æ•°è¿ç®—
  - å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–

---

## ğŸ” å…³é”®å­¦ä¹ ç‚¹æ€»ç»“

### 1. **å…±äº«å†…å­˜çš„ä½¿ç”¨æ¨¡å¼**

```cpp
// åŠ¨æ€åˆ†é…å…±äº«å†…å­˜
extern __shared__ char smem[];

// æ‰‹åŠ¨å¸ƒå±€
T* q_shared = reinterpret_cast<T*>(smem);
T* k_shared = reinterpret_cast<T*>(smem + offset1);
float* kv_shared = reinterpret_cast<float*>(smem + offset2);
```

**ä¼˜åŠ¿**ï¼š
- å®Œå…¨æ§åˆ¶å†…å­˜å¸ƒå±€
- æœ€å¤§åŒ–å…±äº«å†…å­˜åˆ©ç”¨ç‡
- é¿å…é‡å¤å†…å­˜è®¿é—®

### 2. **çº¿ç¨‹ç´¢å¼•è®¡ç®—**

```cpp
const int32_t tid = threadIdx.x;           // Block å†…ç´¢å¼•
const int32_t bid = blockIdx.x;            // Block ç´¢å¼•
const int32_t global_id = bid * blockDim.x + tid;  // å…¨å±€ç´¢å¼•
```

**æ¨¡å¼**ï¼š
- **æ¯ä¸ª head ä¸€ä¸ª block**ï¼šç®€åŒ–åŒæ­¥
- **Grid-Stride Loop**ï¼šå¤„ç†ä»»æ„å¤§å°æ•°ç»„
- **å¤šç»´ç´¢å¼•**ï¼š`b = bid / num_heads`, `h = bid % num_heads`

### 3. **å‘é‡åŒ–æŠ€å·§**

```cpp
uint32_t vec_size = 16 / sizeof(c_type);  // è‡ªåŠ¨è®¡ç®—å‘é‡å¤§å°
dim3 block(std::min(d / vec_size, 1024U));  // æ ¹æ®å‘é‡å¤§å°è°ƒæ•´ block
```

**å…³é”®**ï¼š
- ä¸€æ¬¡åŠ è½½/å­˜å‚¨å¤šä¸ªå…ƒç´ 
- æé«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
- å‡å°‘æŒ‡ä»¤æ•°

### 4. **èåˆæ“ä½œï¼ˆFused Operationsï¼‰**

SGLang å¤§é‡ä½¿ç”¨èåˆæ“ä½œï¼Œå¦‚ï¼š
- **SiLU and Mul**ï¼š`out = silu(x[:d]) * x[d:]`
- **Attention + KV Update**ï¼šåŒæ—¶è®¡ç®—æ³¨æ„åŠ›å’Œæ›´æ–° cache

**ä¼˜åŠ¿**ï¼š
- å‡å°‘å†…å­˜è®¿é—®
- æé«˜ç¼“å­˜åˆ©ç”¨ç‡
- é™ä½ kernel å¯åŠ¨å¼€é”€

---

## ğŸ“š å­¦ä¹ è·¯å¾„å»ºè®®

### é˜¶æ®µ 1ï¼šåŸºç¡€æ“ä½œï¼ˆâ­â­ï¼‰

1. **Copy Kernel**ï¼šç†è§£æœ€åŸºæœ¬çš„ CUDA kernel
2. **æ¿€æ´»å‡½æ•°**ï¼šå­¦ä¹ è®¾å¤‡ç«¯å‡½æ•°å’Œç±»å‹è½¬æ¢
3. **ç®€å•çš„é€å…ƒç´ æ“ä½œ**ï¼šç†è§£ Grid-Stride Loop

### é˜¶æ®µ 2ï¼šä¸­çº§æ“ä½œï¼ˆâ­â­â­ï¼‰

1. **RoPE**ï¼šå­¦ä¹ å¤æ‚çš„æ•°å­¦è¿ç®—å’Œå†…å­˜è®¿é—®
2. **Lightning Attention Decode**ï¼šå­¦ä¹ å…±äº«å†…å­˜å’Œçº¿ç¨‹åä½œ
3. **TopKï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼šå­¦ä¹ æ’åºç®—æ³•

### é˜¶æ®µ 3ï¼šé«˜çº§æ“ä½œï¼ˆâ­â­â­â­â­ï¼‰

1. **å®Œæ•´çš„ TopK**ï¼šå­¦ä¹ åŸºæ•°æ’åºå’Œå¤æ‚ç®—æ³•
2. **GEMM ä¼˜åŒ–**ï¼šå­¦ä¹ çŸ©é˜µä¹˜æ³•çš„ä¼˜åŒ–æŠ€å·§
3. **MoE ç›¸å…³**ï¼šå­¦ä¹ æ··åˆä¸“å®¶çš„å®ç°

---

## ğŸ’¡ å®è·µå»ºè®®

### 1. ä»ç®€å•å¼€å§‹

å…ˆç†è§£ç®€å•çš„ kernelï¼ˆå¦‚ copyã€activationï¼‰ï¼Œå†å­¦ä¹ å¤æ‚çš„ï¼ˆå¦‚ attentionï¼‰ã€‚

### 2. ç”»å›¾ç†è§£

å¯¹äºå¤æ‚çš„ kernelï¼Œç”»å‡ºï¼š
- çº¿ç¨‹åˆ†é…å›¾
- å…±äº«å†…å­˜å¸ƒå±€å›¾
- æ•°æ®æµå›¾

### 3. è¿è¡Œè°ƒè¯•

ä½¿ç”¨ `nsight-compute` æˆ– `cuda-gdb` è°ƒè¯•ï¼š
```bash
ncu --set full ./your_program
cuda-gdb ./your_program
```

### 4. å¯¹æ¯”å­¦ä¹ 

å¯¹æ¯” SGLang å’Œ PyTorch çš„å®ç°ï¼š
- ç†è§£ä¸ºä»€ä¹ˆ SGLang æ›´ç®€å•
- å­¦ä¹ ä¸¤è€…çš„ä¼˜åŒ–æ€è·¯
- æ‰¾åˆ°é€‚åˆè‡ªå·±çš„ç¼–ç¨‹é£æ ¼

---

## ğŸ”— ç›¸å…³èµ„æº

- **SGLang å®˜æ–¹æ–‡æ¡£**ï¼šhttps://github.com/sgl-project/sglang
- **FlashInfer**ï¼šSGLang ä½¿ç”¨çš„æ³¨æ„åŠ›åº“
- **CUTLASS**ï¼šNVIDIA çš„çŸ©é˜µä¹˜æ³•åº“

---

## ğŸ“ æ€»ç»“

SGLang çš„ CUDA ä»£ç ç›¸æ¯” PyTorchï¼š

âœ… **æ›´ç›´æ¥**ï¼šæ²¡æœ‰å¤šå±‚æŠ½è±¡  
âœ… **æ›´æ˜“å­¦**ï¼šä»£ç ç»“æ„æ¸…æ™°  
âœ… **æ›´å®ç”¨**ï¼šä¸“æ³¨ LLM æ¨ç†çš„æ ¸å¿ƒæ“ä½œ  
âœ… **æ›´å¯æ§**ï¼šå®Œå…¨æ§åˆ¶ä¼˜åŒ–ç»†èŠ‚  

**æ¨èå­¦ä¹ é¡ºåº**ï¼š
1. Copy â†’ Activation â†’ RoPE
2. Lightning Attention Decode
3. TopK â†’ GEMM â†’ MoE

è¿™æ ·çš„å­¦ä¹ è·¯å¾„èƒ½è®©ä½ ï¼š
- å¿«é€ŸæŒæ¡ CUDA ç¼–ç¨‹çš„æ ¸å¿ƒæ¦‚å¿µ
- ç†è§£ GPU ä¼˜åŒ–çš„å®é™…æŠ€å·§
- å­¦ä¼šå¦‚ä½•ç¼–å†™é«˜æ€§èƒ½çš„ kernel

